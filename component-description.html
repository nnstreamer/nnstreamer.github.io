<!DOCTYPE html>
<html lang="en">
<head>

<base href=".">

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">


<title>Component description</title>

<link rel="stylesheet" href="assets/css/dark-frontend.css" type="text/css" title="dark">
<link rel="alternate stylesheet" href="assets/css/light-frontend.css" type="text/css" title="light">
<link rel="stylesheet" href="assets/css/bootstrap-toc.min.css" type="text/css">
<link rel="stylesheet" href="assets/css/jquery.mCustomScrollbar.min.css">
<link rel="stylesheet" href="assets/js/search/enable_search.css" type="text/css">

<link rel="stylesheet" href="assets/css/extra_frontend.css" type="text/css">

<link rel="stylesheet" href="assets/css/prism-tomorrow.css" type="text/css" title="dark">

<link rel="alternate stylesheet" href="assets/css/prism.css" type="text/css" title="light">

<script src="assets/js/mustache.min.js"></script>
<script src="assets/js/jquery.js"></script>
<script src="assets/js/bootstrap.js"></script>
<script src="assets/js/scrollspy.js"></script>
<script src="assets/js/typeahead.jquery.min.js"></script>
<script src="assets/js/search.js"></script>
<script src="assets/js/compare-versions.js"></script>
<script src="assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
<script src="assets/js/bootstrap-toc.min.js"></script>
<script src="assets/js/jquery.touchSwipe.min.js"></script>
<script src="assets/js/anchor.min.js"></script>
<script src="assets/js/tag_filtering.js"></script>
<script src="assets/js/language_switching.js"></script>
<script src="assets/js/styleswitcher.js"></script>

<script src="assets/js/lines_around_headings.js"></script>

<script src="assets/js/prism-core.js"></script>
<script src="assets/js/prism-autoloader.js"></script>
<script src="assets/js/prism_autoloader_path_override.js"></script>
<script src="assets/js/trie.js"></script>

<link rel="icon" type="image/png" href="assets/images/nnstreamer_logo.png">

</head>

<body class="no-script
">

<script>
$('body').removeClass('no-script');
</script>

<nav class="navbar navbar-fixed-top navbar-default" id="topnav">
	<div class="container-fluid">
		<div class="navbar-right">
			<a id="toc-toggle">
				<span class="glyphicon glyphicon-menu-right"></span>
				<span class="glyphicon glyphicon-menu-left"></span>
			</a>
			<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-wrapper" aria-expanded="false">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			<span title="light mode switch" class="glyphicon glyphicon-sunglasses pull-right" id="lightmode-icon"></span>
			<form class="navbar-form pull-right" id="navbar-search-form">
                               <div class="form-group has-feedback">
                                       <input type="text" class="form-control input-sm" name="search" id="sidenav-lookup-field" placeholder="search" disabled>
				       <span class="glyphicon glyphicon-search form-control-feedback" id="search-mgn-glass"></span>
                               </div>
                        </form>
		</div>
		<div class="navbar-header">
			<a id="sidenav-toggle">
				<span class="glyphicon glyphicon-menu-right"></span>
				<span class="glyphicon glyphicon-menu-left"></span>
			</a>
			<a id="home-link" href="index.html" class="hotdoc-navbar-brand">
				<img src="assets/images/nnstreamer_logo.png" alt="Home">
			</a>
		</div>
		<div class="navbar-collapse collapse" id="navbar-wrapper">
			<ul class="nav navbar-nav" id="menu">
				
<li class="dropdown">
    <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
        API References<span class="caret"></span>
    </a>
	<ul class="dropdown-menu" id="modules-menu">
					<li>
				<a href="doc-index.html">NNStreamer doc</a>
			</li>
					<li>
				<a href="gst/nnstreamer/README.html">NNStreamer Elements</a>
			</li>
					<li>
				<a href="nnstreamer-example/index.html">NNStreamer Examples</a>
			</li>
					<li>
				<a href="API-reference.html">API reference</a>
			</li>
		</ul>
</li>

<li>
	<a href="doc-index.html">Documents</a>
</li>
<li>
	<a href="gst/nnstreamer/README.html">Elements</a>
</li>
<li>
	<a href="tutorials.html">Tutorials</a>
</li>
<li>
	<a href="API-reference.html">API reference</a>
</li>

			</ul>
			<div class="hidden-xs hidden-sm navbar-text navbar-center">
							</div>
		</div>
	</div>
</nav>

<main>
<div data-extension="core" data-hotdoc-in-toplevel="True" data-hotdoc-project="NNStreamer" data-hotdoc-ref="component-description.html" class="page_container" id="page-wrapper">
<script src="assets/js/utils.js"></script>

<div class="panel panel-collapse oc-collapsed" id="sidenav" data-hotdoc-role="navigation">
	<script src="assets/js/full-width.js"></script>
  <div id="sitenav-wrapper">
    <iframe src="hotdoc-sitemap.html" id="sitenav-frame"></iframe>
  </div>
</div>

<div id="body">
	<div id="main">
				    <div id="page-description" data-hotdoc-role="main">
        <h1 id="gstreamer-stream-data-types">Gstreamer Stream Data Types</h1>
<ul>
<li>other/tensor (obsolete! use <code>other/tensors,num_tensors=1</code> instead)</li>
<li>other/tensors</li>
</ul>
<p>Each frame of an <code>other/tensor</code> or <code>other/tensors</code> stream should have only ONE instance of other/tensor or other/tensors.</p>
<p>Except <code>tensor_decoder</code>, which accepts data semantics from pipeline developers, and <code>tensor_converter</code>, which accepts data semantics from sink pad caps, every NNStreamer tensor plugin and tensor stream should be agnostic to the data semantics. With data semantics, we know whether the corresponding tensor denotes for video, audio, text, or any other "meaningful data types". The NNStreamer elements and data-pipeline, being agnostic to such semantics, should treat every other/tensor and other/tensors as multi-dimensional arrays of general numbers. This allows inter-operability between different neural network models and frameworks. The semantics of tensors should be handled and encapsulated by their direct accessors: the pipeline writer (or the application) and the corresponding framework (and its subplugin).</p>
<h1 id="gstreamer-elements-plugins">Gstreamer Elements (Plugins)</h1>
<p>Note that "stable" does not mean that it is complete. It means that it has enough test cases and complies with the overall design; thus, "stable" features probably won't be modified extensively. Features marked "experimental" can be modified extensively due to its incomplete design and implementation or crudeness. "Planned" is still in the works so it will be released soon.</p>
<p>In this page, we focus on the status of each elements. For requirements and designs of each element, please refer to the README.md of the element. Refer to the papers, <a href="https://arxiv.org/pdf/2101.06371">ICSE2021</a> and <a href="https://arxiv.org/abs/2201.06026">ICSE2022</a> for alternative descriptions on these elements along with some figures.</p>
<ul>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/blob/main/gst/nnstreamer/elements/gsttensor_converter.md">tensor_converter</a>
<ul>
<li>Video (stable)
<ul>
<li>'''video/x-raw'''. Colorspaces of RGB, BGRx, Gray8 are supported.</li>
<li>Caution: if width is not divisible by 4, RGB/Gray8 video incurs memcpy.</li>
</ul>
</li>
<li>Audio (stable)
<ul>
<li>'''audio/x-raw'''. Users should specify the number of frames in a single buffer, which denotes the number of frames in a single tensor frame with the property of <code>frames-per-buffer</code>. Needs more test cases.</li>
</ul>
</li>
<li>Text (stable)
<ul>
<li>'''text/x-raw'''. Users should specify the byte size of a single tensor frame with the property <code>input-dim</code>. Needs more test cases.</li>
</ul>
</li>
<li>Binary (stable)
<ul>
<li>'''application/octet-stream'''. Stream pipeline developer MUST specify the corresponding type and dimensions via properties (input-dim, input-type)</li>
</ul>
</li>
<li>Custom subplugins (stable)
<ul>
<li>FlatBuf (stable): '''other/flatbuf-tensor''' --&gt; '''other/tensors'''</li>
<li>ProtoBuf (stable): '''other/protobuf-tensor''' --&gt; '''other/tensors'''</li>
<li>FlatBuf::FlatBuf (stable): '''other/flexbuf''' --&gt; '''other/tensors'''</li>
<li>Python3 (stable): You may define your own conversion mechanism with python script.</li>
<li>Developers may add their own custom converter subplugin with the APIs defined in <code>nnstreamer_plugin_api_converter.h</code>. Such subplugins may be added in run-time, which is supposed to be installed at the path designated by <code>decoders</code> path in <code>nnstreamer.ini</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/tensor_filter">tensor_filter</a>
<ul>
<li>Main (stable)
<ul>
<li>Supported features
<ul>
<li>Fixed input/output dimensions (fixed by subplugin)</li>
<li>Flexible dimensions (output dimension determined by subplugin according to the input dimension determined by pipeline initialization)</li>
<li>Invoke subplugin with pre-allocated buffers</li>
<li>Invoke subplugin and let subplugin allocate output buffers.</li>
<li>Accept <code>other/tensors</code> with static and flexible format.</li>
<li>Users can add subplugins in run-time.</li>
</ul>
</li>
<li>TODO: Allow to manage synchronization policies.</li>
</ul>
</li>
<li>Custom-C (stable)</li>
<li>Custom-C++-Class (stable)</li>
<li>Custom-C-Easy (stable) (single function ops. basis for lambda functions in the future)</li>
<li>Custom-Python (stable) (~~2.7 and~~ 3)</li>
<li>Custom-LUA (stable)</li>
<li>Custom Native Functions (stable) (Supply custom-filter in run-time)</li>
<li>Tensorflow (stable) (1.09, 1.13, 2.3, 2.7, 2.8 tested)</li>
<li>Tensorflow-lite (stable) (1.09, 1.13, 2.3, 2.7, 2.8 tested)
<ul>
<li>For tensorflow-lite version 2.x, use <code>tensorflow2-lite</code> as the subplugin name, which allows to use both tensorflow-lite 1.x and 2.x simultaneously in a pipeline.</li>
</ul>
</li>
<li>Caffe2 (stable)</li>
<li>PyTorch (stable)</li>
<li>TVM (stable)</li>
<li>NNTrainer (stable. <strong>maintained by its own community</strong>)</li>
<li>TRIx NPU/Samsung (stable. <strong>maintained by the manufacturer</strong>)</li>
<li>Movidius-X NCS2/Intel (stable)</li>
<li>NNFW-Runtime/nnfw (stable)</li>
<li>Edge-TPU/Google (stable)</li>
<li>openVINO/Intel (stable)</li>
<li>ARMNN (stable)</li>
<li>SNPE/Qualcomm (stable for both v1 and v2)</li>
<li>QNN/Qualcomm (stable)</li>
<li>Vivante/Verisilicon (stable)</li>
<li>TensorRT/NVidia (stable)</li>
<li>SNAP (stable)</li>
<li>DeepViewRT/NXP (stable. <strong>maintained by the manufacturer</strong>)</li>
<li>ONNX Runtime (stable)</li>
<li>MXNet (experimental)</li>
<li>Mediapipe (experimental)</li>
<li>ExecuTorch (experimental)</li>
<li>NCNN (experimental)</li>
<li>DALI/NVIDIA (experimental)</li>
<li><a href="writing-subplugin-tensor-filter.html">Guide on writing a filter subplugin</a></li>
<li><a href="https://github.com/nnstreamer/nnstreamer-example/tree/main/templates">Codegen and code template for tensor_filter subplugin</a></li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_transform.md">tensor_transform</a> (stable)
<ul>
<li>Supported features
<ul>
<li>Type Cast (typecast) (stable, orc supported with the property <code>acceleration</code>)</li>
<li>Dimension Change (dimchg) (stable with limited sub features)</li>
<li>Arithmetic (arithmetic) (stable, orc supported with the property <code>acceleration</code>)</li>
<li>Transpose (transpose) (stable with limited sub features)</li>
<li>Standardization/Normalization (stand) (stable with limited sub features)</li>
<li>More features coming soon!</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_decoder.md">tensor_decoder</a> (stable, but with NYI WIP items)
<ul>
<li>Supported features
<ul>
<li>Direct video conversion (video/x-raw) (stable)</li>
<li>Image classification labeling (text/x-raw) (stable)</li>
<li>Bounding boxes (video/x-raw) (stable)
<ul>
<li>This supports different standards, which can be configured at run-time.</li>
</ul>
</li>
<li>Image segmentation (video/x-raw) (stable) and depth</li>
<li>Body pose (video/x-raw) (stable)</li>
<li>Flatbuf (stable)</li>
<li>Flexbuf (stable)</li>
<li>Protobuf (stable)</li>
<li>binary/octet-stream (stable)</li>
</ul>
</li>
<li>Users can add plugins in run-time.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_sink.md">tensor_sink</a> (stable)
<ul>
<li>
<code>appsink</code>-like element, which is specialized for <code>other/tensors</code>. You may use appsink with capsfilter instead.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_merge.c">tensor_merge</a> (stable)
<ul>
<li>This combines multiple single-tensored (<code>other/tensors,num_tensors=1</code>) streams into a single-tensored stream by merging dimensions of incoming tensor streams. For example, it may merge two <code>dimensions=640:480</code> streams into <code>dimensons=1280:480</code>, <code>dimensions=640:960</code>, or <code>dimensions=640:480:2</code>, according to a given configuration.</li>
<li>Users can adjust sync-mode and sync-option to change its behaviors of when to create output tensors and how to choose input tensors.</li>
<li>Users can adjust how dimensions are merged (the rank merged, the order of merged streams).</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_split.c">tensor_split</a> (stable)
<ul>
<li>This is the opposite of <code>tensor_merge</code>. This splits a single-tensored (<code>other/tensors,num_tensors=1</code>) stream into multiple single-tensored streams. For example, a stream of <code>dimensions=1920:1080</code> may split into <code>dimensions=1080:1080</code> and <code>dimensions=840:1080</code>.</li>
<li>Users can adjust how dimensions are split</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/tensor_mux">tensor_mux</a> (stable)
<ul>
<li>This combines multiple <code>other/tensor(s)</code> streams into a single <code>other/tensors</code> stream while keeping the input stream dimensions. Thus, the number of tensors (<code>num_tensors</code>) increase accordingly without changing dimensions of incoming tensors. For example, merging the two tensor streams, <code>num_tensors=1,dimensions=3:2</code> and <code>num_tensors=1,dimensions=4:4:4</code> becomes <code>num_tensors=2,dimensions=3:2,4:4:4</code>, combining frames from the two streams, enforcing synchronization.</li>
<li>Both merge and mux combine multiple streams into a stream; however, merge combines multiple tensors into a tensor, updating the dimensions while mux keep the tensors and combine them into a single container.</li>
<li>Users can adjust sync-mode and sync-option to change its behaviors of when to create output tensors and how to choose input tensors..</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_demux.c">tensor_demux</a> (stable)
<ul>
<li>This decomposes multi-tensor (<code>num_tensors &gt; 1</code>) tensor streams into multiple tensor streams without touching their dimensions. For example, we may split a tensor stream of <code>num_tensors=3,dimensions=5,4,3</code> into <code>num_tensors=2,dimensions=5,4</code> and <code>num_tensors=1,dimensions=3</code>. Users may configure how the tensors split into (e.g., from <code>num_tensors=6</code>, into 3:2:1, 4:2, 1:1:1:1:1:1, or so on, reordering as well).</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_aggregator.md">tensor_aggregator</a> (stable)
<ul>
<li>This combines multiple frames of tensors into a frame in a single tensor stream. For example, it may aggregate two frames into a frame and reduce the framerate into half: <code>dimensions=300:300,framerate=30/1</code> --&gt; <code>dimensions=300:300:2,framerate=15/1</code>.</li>
<li>Users can adjust how frames are aggregated including how many frames are aggregated, how many frames are skipped after each aggregation, which frames are aggregated, which dimension is merged, and so on.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_reposink.c">tensor_repo_sink</a> (stable)
<ul>
<li>This allows to create circular tensor streams by pairing up with <code>tensor_repo_src</code>. Although gstreamer does not allow circular streams, with a pair of <code>tensor_repo_sink/src</code> we can transmit tensor data without actually connecting gstreamer src/sink pads. It is called <code>tensor_repo_*</code> because the src/sink pair shares a tensor repository.</li>
<li>In the pair, <code>tensor_repo_sink</code> is the entering point of the tensor frames. When you create a circular stream, sending back tensors from "behind" to the "front", this element is supposed to be located at the "behind".</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_reposrc.c">tensor_repo_src</a> (stable)
<ul>
<li>This allows to create circular tensor streams by pairing up with <code>tensor_repo_sink</code>. Although gstreamer does not allow circular streams, with a pair of <code>tensor_repo_sink/src</code> we can transmit tensor data without actually connecting gstreamer src/sink pads. It is called <code>tensor_repo_*</code> because the src/sink pair shares a tensor repository.</li>
<li>In the pair, <code>tensor_repo_src</code> is the exit point of the tensor frames. When you create a circular stream, sending back tensors from "behind" to the "front", this element is supposed to be located at the "front".</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_if.md">tensor_if</a> (stable)
<ul>
<li>This element controls the flow or tensor data based on the given decision condition and the input tensor data. Unlike other similar gstreamer elements, including <code>valve</code>, <code>input-selector</code>, or <code>output-selector</code>, which decides based on the property value given by threads out of the pipeline, this element, <code>tensor_if</code>, decides based on the stream data in the pipeline. Thus, pipelines can switch between their sub-pipelines (e.g., input nodes, output nodes, and processing nodes) precisely (without losing a frame or two) if they should decide based on an inference result or sensor data.</li>
<li>This element allows a lot of varying configurations and users can even provide a C function callback for conditions; please refer to its documentation.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_sparseenc.c">tensor_sparse_enc</a> (stable)
<ul>
<li>This transforms <code>other/tensors,format=static</code> to <code>other/tensors,format=sparse</code>, encoding tensor data frames that may compress data size of sparse tensors.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_sparsedec.c">tensor_sparse_dec</a> (stable)
<ul>
<li>This transforms <code>other/tensors,format=sparse</code> to <code>other/tensors,format=static</code>.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/tensor_query">tensor_query_client</a> (stable)
<ul>
<li>This element sends queries to and receives answers from <code>tensor_query_server{sink, src}</code> elements. This works as if this is a <code>tensor_filter</code> with a remote processing element. This is a basic among-device AI capability that is supposed to offload inference workloads to different devices.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/tensor_query">tensor_query_serversrc</a> (stable)
<ul>
<li>This element receives queries from remote (out of its pipeline) <code>tensor_query_client</code> or its compatible component of <code>nnstreamer-edge</code>.</li>
<li>This element behaves as an entry point of a server or service element for remote clients, accepting offload requests.</li>
<li>Users constructing a "server" pipeline are supposed to use this element as an entry point (input node).</li>
<li>If you use service construct of ML-Service-API, you need a single pair of <code>tensor_query_server{src, sink}</code> in your registered pipeline.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/tensor_query">tensor_query_serversink</a> (stable)
<ul>
<li>This element sends back answers of given queries to remote (out of its pipeline) <code>tensor_query_client</code>, which is connected to the paired <code>tensor_query_serversrc</code>. The server elements are supposed to be paired-up so that the query-sending client gets the corresponding answers.</li>
<li>Users constructing a "server" pipeline are supposed to use this element as an exit point (output node).</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_crop.c">tensor_crop</a> (stable)
<ul>
<li>This element crops a tensor stream based on the values of another tensor stream. Unlike the conventional gstreamer crop elements, which crop data frames based on the property values given outside from the pipeline, this element crop data frames based on the streamed values in the pipeline. Thus, users can crop tensors with the inference results or sensor data directly without involving external threads; e.g., cropping out detected objects from a video stream, to create a video stream focussing on a specific object. This element uses flexible tensors because the crop-size varies dynamically.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_rate.c">tensor_rate</a> (stable)
<ul>
<li>This element controls a frame rate of tensors streams. Users can also control QoS with throttle property.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer/elements/gsttensor_src.md">tensor_src_iio</a> (stable)
<ul>
<li>Requires GStreamer 1.8 or above.</li>
<li>Creates tensor streams from Linux iio (sensors) device nodes.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/ext/nnstreamer/tensor_source">tensor_src_tizensensor</a> (stable)
<ul>
<li>This element imports data from Tizen sensor framework, which can provide sensor-fusion service, and generates tensor stream from it. Obviously, this works only in Tizen.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/ext/nnstreamer/tensor_source">tensor_src_grpc</a> (stable)
<ul>
<li>This element generates tensor streams from data received via grpc connection.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/ext/nnstreamer/tensor_sink">tensor_sink_grpc</a> (stable)
<ul>
<li>This element sends data via grpc connection from tensor streams.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/ext/nnstreamer/android_source">android supports</a> (stable)
<ul>
<li>This element allows to accept data streams from Android's media framework.</li>
</ul>
</li>
</ul>
<p>Elements that do not deal with <code>other/tensors</code> streams, but are in this repo:</p>
<ul>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/join">join</a> (stable)
<ul>
<li>This element combines multiple streams into a stream. This does not merge dimensions or data frames. This simply forwards every incoming frames from multiple sources into a single destination, combining the data stream paths only.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/mqtt">mqttsrc</a> (stable)
<ul>
<li>This element receives tensor stream data via MQTT protocol.</li>
<li>With "mqtt-hybrid" mode, data streams (TCP/direct) can be separated from control streams (MQTT) to increase data throughput.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/mqtt">mqttsink</a> (stable)
<ul>
<li>This element sends tensor stream data via MQTT protocol.</li>
<li>With "mqtt-hybrid" mode, data streams (TCP/direct) can be separated from control streams (MQTT) to increase data throughput.</li>
</ul>
</li>
</ul>
<p>Elements dealing with <code>other/tensors</code> streams, but are in a different repo:</p>
<ul>
<li>
<a href="https://github.com/nnstreamer/nnstreamer-ros">tensor_ros_sink</a> (stable for ROS1/ROS2)
<ul>
<li>You may send tensor streams via ROS pub/sub structure.</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer-ros">tensor_ros_src</a> (stable for ROS1/ROS2)
<ul>
<li>You may receive tensor streams via ROS pub/sub structure.</li>
</ul>
</li>
</ul>
<p>Note that test elements in /tests/ are not elements for applications. They exist as scaffoldings to test the above elements especially in the case where related elements are not yet implemented.</p>
<h1 id="other-components">Other Components</h1>
<ul>
<li>CI (<a href="http://ci.nnstreamer.ai/nnstreamer/ci/taos">@AWS</a>) (stable): Up and Running.</li>
<li>CD
<ul>
<li>Tizen (since 5.5 M1) <a href="https://download.tizen.org/snapshots/TIZEN/Tizen/Tizen-Unified/latest/repos/standard/packages/">Package Download</a> <a href="https://build.tizen.org/project/show/Tizen:Unified">Build &amp; Release Infra</a>
</li>
<li>Ubuntu <a href="https://launchpad.net/%7Ennstreamer/+archive/ubuntu/ppa">Launchpad PPA</a>
</li>
<li>Yocto/OpenEmbedded <a href="https://layers.openembedded.org/layerindex/branch/master/layer/meta-neural-network/">OpenEmbedded Layer, "meta-neural-network"</a>
</li>
<li>Android WIP: JCenter Repository &amp; Daily Build Release</li>
<li>macOS WIP: Daily Build Release</li>
</ul>
</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/tests/">Test cases</a>: Mandatory unit test cases required to pass for each PR.
<ul>
<li>Used <a href="https://github.com/myungjoo/SSAT">SSAT</a>.</li>
<li>Each element and feature is required to register its testcases at <a href="https://github.com/nnstreamer/nnstreamer/tree/main/tests/">test case directory</a>
</li>
</ul>
</li>
<li>Examples: Example GStreamer applications using NNStreamer and example sub-plugins for NNStreamer. The binaries from this directory is not supposed to be packaged with the main binary package.
<ul>
<li><a href="https://github.com/nnstreamer/nnstreamer-example">Example GStreamer applications</a></li>
<li><a href="https://github.com/nnstreamer/nnstreamer/tree/main/nnstreamer_example">Example sub-plugins</a></li>
</ul>
</li>
<li>Packaging for Distros / SW-Platform Compatibility.
<ul>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/packaging">Tizen</a> (stable): RPM packaging for Tizen 5.0+. It is expected to be compatible with other RPM-based distros; however, it is not tested or guaranteed.</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/debian">Ubuntu</a> (stable): DEB packaging for Ubuntu 16.04. It is highly expected to be compatible with later versions as well; but, not tested yet. Debian is not tested, either.</li>
<li>
<a href="https://github.com/nnsuite/meta-nerual-network">Yocto</a> (stable)</li>
<li>
<a href="https://github.com/nnstreamer/nnstreamer/tree/main/jni">Android</a> (stable)</li>
<li>macOS (built &amp; tested w/ macOS. but packaging is not provided, yet.)</li>
<li>iOS (planned with low priority)</li>
</ul>
</li>
<li><a href="https://github.com/nnstreamer/nnstreamer/tree/main/gst/nnstreamer">Common headers</a></li>
<li><a href="https://github.com/nnstreamer/nnstreamer/tree/main/CHANGES">Change Log</a></li>
</ul>

    </div>
        




		
	</div>
	<div id="search_results">
		<p>The results of the search are</p>
	</div>
	<div id="footer">
		    

	</div>
</div>

<div id="toc-column">
	
		<div class="edit-button">
		

	</div>
		<div id="toc-wrapper">
		<nav id="toc"></nav>
	</div>
</div>
</div>
</main>


<script src="assets/js/navbar_offset_scroller.js"></script>
</body>
</html>
