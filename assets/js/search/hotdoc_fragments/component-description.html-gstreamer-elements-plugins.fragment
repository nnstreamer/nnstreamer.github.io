fragment_downloaded_cb({"url":"component-description.html#gstreamer-elements-plugins","fragment":"Gstreamer Elements (Plugins)\nNote that \"stable\" does not mean that it is complete. It means that it has enough test cases and complies with the overall design; thus, \"stable\" features probably won't be modified extensively. Features marked \"experimental\" can be modified extensively due to its incomplete design and implementation or crudeness. \"Planned\" is still in the works so it will be released soon.\nIn this page, we focus on the status of each elements. For requirements and designs of each element, please refer to the README.md of the element. Refer to the papers, ICSE2021 and ICSE2022 for alternative descriptions on these elements along with some figures.\nElements that do not deal with other/tensors streams, but are in this repo:\nElements dealing with other/tensors streams, but are in a different repo:\nNote that test elements in /tests/ are not elements for applications. They exist as scaffoldings to test the above elements especially in the case where related elements are not yet implemented.\n\n\ntensor_converter\n\nVideo (stable)\n\n'''video/x-raw'''. Colorspaces of RGB, BGRx, Gray8 are supported.\nCaution: if width is not divisible by 4, RGB/Gray8 video incurs memcpy.\n\n\nAudio (stable)\n\n'''audio/x-raw'''. Users should specify the number of frames in a single buffer, which denotes the number of frames in a single tensor frame with the property of frames-per-buffer. Needs more test cases.\n\n\nText (stable)\n\n'''text/x-raw'''. Users should specify the byte size of a single tensor frame with the property input-dim. Needs more test cases.\n\n\nBinary (stable)\n\n'''application/octet-stream'''. Stream pipeline developer MUST specify the corresponding type and dimensions via properties (input-dim, input-type)\n\n\nCustom subplugins (stable)\n\nFlatBuf (stable): '''other/flatbuf-tensor''' --> '''other/tensors'''\nProtoBuf (stable): '''other/protobuf-tensor''' --> '''other/tensors'''\nFlatBuf::FlatBuf (stable): '''other/flexbuf''' --> '''other/tensors'''\nPython3 (stable): You may define your own conversion mechanism with python script.\nDevelopers may add their own custom converter subplugin with the APIs defined in nnstreamer_plugin_api_converter.h. Such subplugins may be added in run-time, which is supposed to be installed at the path designated by decoders path in nnstreamer.ini.\n\n\n\n\n\ntensor_filter\n\nMain (stable)\n\nSupported features\n\nFixed input/output dimensions (fixed by subplugin)\nFlexible dimensions (output dimension determined by subplugin according to the input dimension determined by pipeline initialization)\nInvoke subplugin with pre-allocated buffers\nInvoke subplugin and let subplugin allocate output buffers.\nAccept other/tensors with static and flexible format.\nUsers can add subplugins in run-time.\n\n\nTODO: Allow to manage synchronization policies.\n\n\nCustom-C (stable)\nCustom-C++-Class (stable)\nCustom-C-Easy (stable) (single function ops. basis for lambda functions in the future)\nCustom-Python (stable) (~~2.7 and~~ 3)\nCustom-LUA (stable)\nCustom Native Functions (stable) (Supply custom-filter in run-time)\nTensorflow (stable) (1.09, 1.13, 2.3, 2.7, 2.8 tested)\nTensorflow-lite (stable) (1.09, 1.13, 2.3, 2.7, 2.8 tested)\n\nFor tensorflow-lite version 2.x, use tensorflow2-lite as the subplugin name, which allows to use both tensorflow-lite 1.x and 2.x simultaneously in a pipeline.\n\n\nCaffe2 (stable)\nPyTorch (stable)\nTVM (stable)\nNNTrainer (stable. maintained by its own community)\nTRIx NPU/Samsung (stable. maintained by the manufacturer)\nMovidius-X NCS2/Intel (stable)\nNNFW-Runtime/nnfw (stable)\nEdge-TPU/Google (stable)\nopenVINO/Intel (stable)\nARMNN (stable)\nSNPE/Qualcomm (stable)\nVivante/Verisilicon (stable)\nTensorRT/NVidia (stable)\nSNAP (stable)\nDeepview-RT/NXP (stable. maintained by the manufacturer)\nMXNet (experimental)\nMediapipe (experimental)\nWIP: NCNN\nGuide on writing a filter subplugin\nCodegen and code template for tensor_filter subplugin\n\n\n\ntensor_transform (stable)\n\nSupported features\n\nType Cast (typecast) (stable, orc supported with the property acceleration)\nDimension Change (dimchg) (stable with limited sub features)\nArithmetic (arithmetic) (stable, orc supported with the property acceleration)\nTranspose (transpose) (stable with limited sub features)\nStandardization/Normalization (stand) (stable with limited sub features)\nMore features coming soon!\n\n\n\n\n\ntensor_decoder (stable, but with NYI WIP items)\n\nSupported features\n\nDirect video conversion (video/x-raw) (stable)\nImage classification labeling (text/x-raw) (stable)\nBounding boxes (video/x-raw) (stable)\n\nThis supports different standards, which can be configured at run-time.\n\n\nImage segmentation (video/x-raw) (stable) and depth\nBody pose (video/x-raw) (stable)\nFlatbuf (stable)\nFlexbuf (stable)\nProtobuf (stable)\nbinary/octet-stream (stable)\n\n\nUsers can add plugins in run-time.\n\n\n\ntensor_sink (stable)\n\n\nappsink-like element, which is specialized for other/tensors. You may use appsink with capsfilter instead.\n\n\n\ntensor_merge (stable)\n\nThis combines muiltiple single-tensored (other/tensors,num_tensors=1) streams into a single-tensored stream by merging dimensions of incoming tensor streams. For example, it may merge two dimensions=640:480 streams into dimensons=1280:480, dimensions=640:960, or dimensions=640:480:2, according to a given configuration.\nUsers can adjust sync-mode and sync-option to change its behaviors of when to create output tensors and how to choose input tensors.\nUsers can adjust how dimensions are merged (the rank merged, the order of merged streams).\n\n\n\ntensor_split (stable)\n\nThis is the opposite of tensor_merge. This splits a single-tensored (other/tensors,num_tensors=1) stream into multiple single-tensored streams. For example, a stream of dimensions=1920:1080 may split into dimensions=1080:1080 and dimensions=840:1080.\nUsers can adjust how dimensions are split\n\n\n\ntensor_mux (stable)\n\nThis combines multiple other/tensor(s) streams into a single other/tensors stream while keeping the input stream dimensions. Thus, the number of tensors (num_tensors) increase accordingly without changing dimensions of incoming tensors. For example, merging the two tensor streams, num_tensors=1,dimensions=3:2 and num_tensors=1,dimensions=4:4:4 becomes num_tensors=2,dimensions=3:2,4:4:4, combining frames from the two streams, enforcing synchronization.\nBoth merge and mux combine multiple streams into a stream; however, merge combines multiple tensors into a tensor, updating the dimensions while mux keep the tensors and combine them into a single container.\nUsers can adjust sync-mode and sync-option to change its behaviors of when to create output tensors and how to choose input tensors..\n\n\n\ntensor_demux (stable)\n\nThis decomposes multi-tensor (num_tensors > 1) tensor streams into multiple tensor streams without touching their dimensions. For example, we may split a tensor stream of num_tensors=3,dimensions=5,4,3 into num_tensors=2,dimensions=5,4 and num_tensors=1,dimensions=3. Users may configure how the tensors split into (e.g., from num_tensors=6, into 3:2:1, 4:2, 1:1:1:1:1:1, or so on, reordering as well).\n\n\n\ntensor_aggregator (stable)\n\nThis combines multiple frames of tensors into a frame in a single tensor stream. For example, it may aggregate two frames into a frame and reduce the framerate into half: dimensions=300:300,framerate=30/1 --> dimensions=300:300:2,framerate=15/1.\nUsers can adjust how frames are aggregated including how many frames are aggregated, how many frames are skipped after each aggregation, which frames are aggregated, which dimension is merged, and so on.\n\n\n\ntensor_repo_sink (stable)\n\nThis allows to create circular tensor streams by pairing up with tensor_repo_src. Although gstreamer does not allow circular streams, with a pair of tensor_repo_sink/src we can transmit tensor data without actually connecting gstreamer src/sink pads. It is called tensor_repo_* because the src/sink pair shares a tensor repository.\nIn the pair, tensor_repo_sink is the entering point of the tensor frames. When you create a circular stream, sending back tensors from \"behind\" to the \"front\", this element is supposed to be located at the \"behind\".\n\n\n\ntensor_repo_src (stable)\n\nThis allows to create circular tensor streams by pairing up with tensor_repo_sink. Although gstreamer does not allow circular streams, with a pair of tensor_repo_sink/src we can transmit tensor data without actually connecting gstreamer src/sink pads. It is called tensor_repo_* because the src/sink pair shares a tensor repository.\nIn the pair, tensor_repo_src is the exit point of the tensor frames. When you create a circular stream, sending back tensors from \"behind\" to the \"front\", this element is supposed to be located at the \"front\".\n\n\n\ntensor_if (stable)\n\nThis element controls the flow or tensor data based on the given decision condition and the input tensor data. Unlike other similar gstreamer elements, including valve, input-selector, or output-selector, which decides based on the property value given by threads out of the pipeline, this element, tensor_if, decides based on the stream data in the pipeline. Thus, pipelines can switch between their sub-pipelines (e.g., input nodes, output nodes, and processing nodes) precisely (without losing a frame or two) if they should decide based on an inference result or sensor data.\nThis element allows a lot of varying configurations and users can even provide a C function callback for conditions; please refer to its documentation.\n\n\n\ntensor_sparse_enc (stable)\n\nThis transforms other/tensors,format=static to other/tensors,format=sparse, encoding tensor data frames that may compress data size of sparse tensors.\n\n\n\ntensor_sparse_dec (stable)\n\nThis transforms other/tensors,format=sparse to other/tensors,format=static.\n\n\n\ntensor_query_client (stable)\n\nThis element sends queries to and receives answers from tensor_query_server{sink, src} elements. This works as if this is a tensor_filter with a remote processing element. This is a basic among-device AI capability that is supposed to offload inference workloads to different devices.\n\n\n\ntensor_query_serversrc (stable)\n\nThis element receives queries from remote (out of its pipeline) tensor_query_client or its compatible component of nnstreamer-edge.\nThis element behaves as an entry point of a server or service element for remote clients, accepting offload requests.\nUsers constructing a \"server\" pipeline are supposed to use this element as an entry point (input node).\nIf you use service construct of ML-Service-API, you need a single pair of tensor_query_server{src, sink} in your registered pipeline.\n\n\n\ntensor_query_serversink (stable)\n\nThis element sends back answers of given queries to remote (out of its pipeline) tensor_query_client, which is connected to the paired tensor_query_serversrc. The server elements are supposed to be paired-up so that the query-sending client gets the corresponding answers.\nUsers constructing a \"server\" pipeline are supposed to use this element as an exit point (output node).\n\n\n\ntensor_crop (stable)\n\nThis element crops a tensor stream based on the values of another tensor stream. Unlike the conventional gstreamer crop elements, which crop data frames based on the property values given outside from the pipeline, this element crop data frames based on the streamed values in the pipeline. Thus, users can crop tensors with the inference results or sensor data directly without involving external threads; e.g., cropping out detected objects from a video stream, to create a video stream focussing on a specific object. This element uses flexible tensors because the crop-size varies dynamically.\n\n\n\ntensor_rate (stable)\n\nThis element controls a frame rate of tensors streams. Users can also control QoS with throttle property.\n\n\n\ntensor_src_iio (stable)\n\nRequires GStreamer 1.8 or above.\nCreates tensor streams from Linux iio (sensors) device nodes.\n\n\n\ntensor_src_tizensensor (stable)\n\nThis element imports data from Tizen sensor framework, which can provide sensor-fusion service, and generates tensor stream from it. Obviously, this works only in Tizen.\n\n\n\ntensor_src_grpc (stable)\n\nThis element generates tensor streams from data received via grpc connection.\n\n\n\ntensor_sink_grpc (stable)\n\nThis element sends data via grpc connection from tensor streams.\n\n\n\nandroid supports (stable)\n\nThis element allows to accept data streams from Android's media framework.\n\n\n\n\nVideo (stable)\n\n'''video/x-raw'''. Colorspaces of RGB, BGRx, Gray8 are supported.\nCaution: if width is not divisible by 4, RGB/Gray8 video incurs memcpy.\n\n\nAudio (stable)\n\n'''audio/x-raw'''. Users should specify the number of frames in a single buffer, which denotes the number of frames in a single tensor frame with the property of frames-per-buffer. Needs more test cases.\n\n\nText (stable)\n\n'''text/x-raw'''. Users should specify the byte size of a single tensor frame with the property input-dim. Needs more test cases.\n\n\nBinary (stable)\n\n'''application/octet-stream'''. Stream pipeline developer MUST specify the corresponding type and dimensions via properties (input-dim, input-type)\n\n\nCustom subplugins (stable)\n\nFlatBuf (stable): '''other/flatbuf-tensor''' --> '''other/tensors'''\nProtoBuf (stable): '''other/protobuf-tensor''' --> '''other/tensors'''\nFlatBuf::FlatBuf (stable): '''other/flexbuf''' --> '''other/tensors'''\nPython3 (stable): You may define your own conversion mechanism with python script.\nDevelopers may add their own custom converter subplugin with the APIs defined in nnstreamer_plugin_api_converter.h. Such subplugins may be added in run-time, which is supposed to be installed at the path designated by decoders path in nnstreamer.ini.\n\n\n\n\n'''video/x-raw'''. Colorspaces of RGB, BGRx, Gray8 are supported.\nCaution: if width is not divisible by 4, RGB/Gray8 video incurs memcpy.\n\n\n'''audio/x-raw'''. Users should specify the number of frames in a single buffer, which denotes the number of frames in a single tensor frame with the property of frames-per-buffer. Needs more test cases.\n\n\n'''text/x-raw'''. Users should specify the byte size of a single tensor frame with the property input-dim. Needs more test cases.\n\n\n'''application/octet-stream'''. Stream pipeline developer MUST specify the corresponding type and dimensions via properties (input-dim, input-type)\n\n\nFlatBuf (stable): '''other/flatbuf-tensor''' --> '''other/tensors'''\nProtoBuf (stable): '''other/protobuf-tensor''' --> '''other/tensors'''\nFlatBuf::FlatBuf (stable): '''other/flexbuf''' --> '''other/tensors'''\nPython3 (stable): You may define your own conversion mechanism with python script.\nDevelopers may add their own custom converter subplugin with the APIs defined in nnstreamer_plugin_api_converter.h. Such subplugins may be added in run-time, which is supposed to be installed at the path designated by decoders path in nnstreamer.ini.\n\n\nMain (stable)\n\nSupported features\n\nFixed input/output dimensions (fixed by subplugin)\nFlexible dimensions (output dimension determined by subplugin according to the input dimension determined by pipeline initialization)\nInvoke subplugin with pre-allocated buffers\nInvoke subplugin and let subplugin allocate output buffers.\nAccept other/tensors with static and flexible format.\nUsers can add subplugins in run-time.\n\n\nTODO: Allow to manage synchronization policies.\n\n\nCustom-C (stable)\nCustom-C++-Class (stable)\nCustom-C-Easy (stable) (single function ops. basis for lambda functions in the future)\nCustom-Python (stable) (~~2.7 and~~ 3)\nCustom-LUA (stable)\nCustom Native Functions (stable) (Supply custom-filter in run-time)\nTensorflow (stable) (1.09, 1.13, 2.3, 2.7, 2.8 tested)\nTensorflow-lite (stable) (1.09, 1.13, 2.3, 2.7, 2.8 tested)\n\nFor tensorflow-lite version 2.x, use tensorflow2-lite as the subplugin name, which allows to use both tensorflow-lite 1.x and 2.x simultaneously in a pipeline.\n\n\nCaffe2 (stable)\nPyTorch (stable)\nTVM (stable)\nNNTrainer (stable. maintained by its own community)\nTRIx NPU/Samsung (stable. maintained by the manufacturer)\nMovidius-X NCS2/Intel (stable)\nNNFW-Runtime/nnfw (stable)\nEdge-TPU/Google (stable)\nopenVINO/Intel (stable)\nARMNN (stable)\nSNPE/Qualcomm (stable)\nVivante/Verisilicon (stable)\nTensorRT/NVidia (stable)\nSNAP (stable)\nDeepview-RT/NXP (stable. maintained by the manufacturer)\nMXNet (experimental)\nMediapipe (experimental)\nWIP: NCNN\nGuide on writing a filter subplugin\nCodegen and code template for tensor_filter subplugin\n\n\nSupported features\n\nFixed input/output dimensions (fixed by subplugin)\nFlexible dimensions (output dimension determined by subplugin according to the input dimension determined by pipeline initialization)\nInvoke subplugin with pre-allocated buffers\nInvoke subplugin and let subplugin allocate output buffers.\nAccept other/tensors with static and flexible format.\nUsers can add subplugins in run-time.\n\n\nTODO: Allow to manage synchronization policies.\n\n\nFixed input/output dimensions (fixed by subplugin)\nFlexible dimensions (output dimension determined by subplugin according to the input dimension determined by pipeline initialization)\nInvoke subplugin with pre-allocated buffers\nInvoke subplugin and let subplugin allocate output buffers.\nAccept other/tensors with static and flexible format.\nUsers can add subplugins in run-time.\n\n\nFor tensorflow-lite version 2.x, use tensorflow2-lite as the subplugin name, which allows to use both tensorflow-lite 1.x and 2.x simultaneously in a pipeline.\n\n\nSupported features\n\nType Cast (typecast) (stable, orc supported with the property acceleration)\nDimension Change (dimchg) (stable with limited sub features)\nArithmetic (arithmetic) (stable, orc supported with the property acceleration)\nTranspose (transpose) (stable with limited sub features)\nStandardization/Normalization (stand) (stable with limited sub features)\nMore features coming soon!\n\n\n\n\nType Cast (typecast) (stable, orc supported with the property acceleration)\nDimension Change (dimchg) (stable with limited sub features)\nArithmetic (arithmetic) (stable, orc supported with the property acceleration)\nTranspose (transpose) (stable with limited sub features)\nStandardization/Normalization (stand) (stable with limited sub features)\nMore features coming soon!\n\n\nSupported features\n\nDirect video conversion (video/x-raw) (stable)\nImage classification labeling (text/x-raw) (stable)\nBounding boxes (video/x-raw) (stable)\n\nThis supports different standards, which can be configured at run-time.\n\n\nImage segmentation (video/x-raw) (stable) and depth\nBody pose (video/x-raw) (stable)\nFlatbuf (stable)\nFlexbuf (stable)\nProtobuf (stable)\nbinary/octet-stream (stable)\n\n\nUsers can add plugins in run-time.\n\n\nDirect video conversion (video/x-raw) (stable)\nImage classification labeling (text/x-raw) (stable)\nBounding boxes (video/x-raw) (stable)\n\nThis supports different standards, which can be configured at run-time.\n\n\nImage segmentation (video/x-raw) (stable) and depth\nBody pose (video/x-raw) (stable)\nFlatbuf (stable)\nFlexbuf (stable)\nProtobuf (stable)\nbinary/octet-stream (stable)\n\n\nThis supports different standards, which can be configured at run-time.\n\n\n\nappsink-like element, which is specialized for other/tensors. You may use appsink with capsfilter instead.\n\n\nThis combines muiltiple single-tensored (other/tensors,num_tensors=1) streams into a single-tensored stream by merging dimensions of incoming tensor streams. For example, it may merge two dimensions=640:480 streams into dimensons=1280:480, dimensions=640:960, or dimensions=640:480:2, according to a given configuration.\nUsers can adjust sync-mode and sync-option to change its behaviors of when to create output tensors and how to choose input tensors.\nUsers can adjust how dimensions are merged (the rank merged, the order of merged streams).\n\n\nThis is the opposite of tensor_merge. This splits a single-tensored (other/tensors,num_tensors=1) stream into multiple single-tensored streams. For example, a stream of dimensions=1920:1080 may split into dimensions=1080:1080 and dimensions=840:1080.\nUsers can adjust how dimensions are split\n\n\nThis combines multiple other/tensor(s) streams into a single other/tensors stream while keeping the input stream dimensions. Thus, the number of tensors (num_tensors) increase accordingly without changing dimensions of incoming tensors. For example, merging the two tensor streams, num_tensors=1,dimensions=3:2 and num_tensors=1,dimensions=4:4:4 becomes num_tensors=2,dimensions=3:2,4:4:4, combining frames from the two streams, enforcing synchronization.\nBoth merge and mux combine multiple streams into a stream; however, merge combines multiple tensors into a tensor, updating the dimensions while mux keep the tensors and combine them into a single container.\nUsers can adjust sync-mode and sync-option to change its behaviors of when to create output tensors and how to choose input tensors..\n\n\nThis decomposes multi-tensor (num_tensors > 1) tensor streams into multiple tensor streams without touching their dimensions. For example, we may split a tensor stream of num_tensors=3,dimensions=5,4,3 into num_tensors=2,dimensions=5,4 and num_tensors=1,dimensions=3. Users may configure how the tensors split into (e.g., from num_tensors=6, into 3:2:1, 4:2, 1:1:1:1:1:1, or so on, reordering as well).\n\n\nThis combines multiple frames of tensors into a frame in a single tensor stream. For example, it may aggregate two frames into a frame and reduce the framerate into half: dimensions=300:300,framerate=30/1 --> dimensions=300:300:2,framerate=15/1.\nUsers can adjust how frames are aggregated including how many frames are aggregated, how many frames are skipped after each aggregation, which frames are aggregated, which dimension is merged, and so on.\n\n\nThis allows to create circular tensor streams by pairing up with tensor_repo_src. Although gstreamer does not allow circular streams, with a pair of tensor_repo_sink/src we can transmit tensor data without actually connecting gstreamer src/sink pads. It is called tensor_repo_* because the src/sink pair shares a tensor repository.\nIn the pair, tensor_repo_sink is the entering point of the tensor frames. When you create a circular stream, sending back tensors from \"behind\" to the \"front\", this element is supposed to be located at the \"behind\".\n\n\nThis allows to create circular tensor streams by pairing up with tensor_repo_sink. Although gstreamer does not allow circular streams, with a pair of tensor_repo_sink/src we can transmit tensor data without actually connecting gstreamer src/sink pads. It is called tensor_repo_* because the src/sink pair shares a tensor repository.\nIn the pair, tensor_repo_src is the exit point of the tensor frames. When you create a circular stream, sending back tensors from \"behind\" to the \"front\", this element is supposed to be located at the \"front\".\n\n\nThis element controls the flow or tensor data based on the given decision condition and the input tensor data. Unlike other similar gstreamer elements, including valve, input-selector, or output-selector, which decides based on the property value given by threads out of the pipeline, this element, tensor_if, decides based on the stream data in the pipeline. Thus, pipelines can switch between their sub-pipelines (e.g., input nodes, output nodes, and processing nodes) precisely (without losing a frame or two) if they should decide based on an inference result or sensor data.\nThis element allows a lot of varying configurations and users can even provide a C function callback for conditions; please refer to its documentation.\n\n\nThis transforms other/tensors,format=static to other/tensors,format=sparse, encoding tensor data frames that may compress data size of sparse tensors.\n\n\nThis transforms other/tensors,format=sparse to other/tensors,format=static.\n\n\nThis element sends queries to and receives answers from tensor_query_server{sink, src} elements. This works as if this is a tensor_filter with a remote processing element. This is a basic among-device AI capability that is supposed to offload inference workloads to different devices.\n\n\nThis element receives queries from remote (out of its pipeline) tensor_query_client or its compatible component of nnstreamer-edge.\nThis element behaves as an entry point of a server or service element for remote clients, accepting offload requests.\nUsers constructing a \"server\" pipeline are supposed to use this element as an entry point (input node).\nIf you use service construct of ML-Service-API, you need a single pair of tensor_query_server{src, sink} in your registered pipeline.\n\n\nThis element sends back answers of given queries to remote (out of its pipeline) tensor_query_client, which is connected to the paired tensor_query_serversrc. The server elements are supposed to be paired-up so that the query-sending client gets the corresponding answers.\nUsers constructing a \"server\" pipeline are supposed to use this element as an exit point (output node).\n\n\nThis element crops a tensor stream based on the values of another tensor stream. Unlike the conventional gstreamer crop elements, which crop data frames based on the property values given outside from the pipeline, this element crop data frames based on the streamed values in the pipeline. Thus, users can crop tensors with the inference results or sensor data directly without involving external threads; e.g., cropping out detected objects from a video stream, to create a video stream focussing on a specific object. This element uses flexible tensors because the crop-size varies dynamically.\n\n\nThis element controls a frame rate of tensors streams. Users can also control QoS with throttle property.\n\n\nRequires GStreamer 1.8 or above.\nCreates tensor streams from Linux iio (sensors) device nodes.\n\n\nThis element imports data from Tizen sensor framework, which can provide sensor-fusion service, and generates tensor stream from it. Obviously, this works only in Tizen.\n\n\nThis element generates tensor streams from data received via grpc connection.\n\n\nThis element sends data via grpc connection from tensor streams.\n\n\nThis element allows to accept data streams from Android's media framework.\n\n\n\njoin (stable)\n\nThis element combines multiple streams into a stream. This does not merge dimensions or data frames. This simply forwards every incoming frames from multiple sources into a single destination, combining the data stream paths only.\n\n\n\nmqttsrc (stable)\n\nThis element receives tensor stream data via MQTT protocol.\nWith \"mqtt-hybrid\" mode, data streams (TCP/direct) can be separated from control streams (MQTT) to increase data throughput.\n\n\n\nmqttsink (stable)\n\nThis element sends tensor stream data via MQTT protocol.\nWith \"mqtt-hybrid\" mode, data streams (TCP/direct) can be separated from control streams (MQTT) to increase data throughput.\n\n\n\n\nThis element combines multiple streams into a stream. This does not merge dimensions or data frames. This simply forwards every incoming frames from multiple sources into a single destination, combining the data stream paths only.\n\n\nThis element receives tensor stream data via MQTT protocol.\nWith \"mqtt-hybrid\" mode, data streams (TCP/direct) can be separated from control streams (MQTT) to increase data throughput.\n\n\nThis element sends tensor stream data via MQTT protocol.\nWith \"mqtt-hybrid\" mode, data streams (TCP/direct) can be separated from control streams (MQTT) to increase data throughput.\n\n\n\ntensor_ros_sink (stable for ROS1/ROS2)\n\nYou may send tensor streams via ROS pub/sub structure.\n\n\n\ntensor_ros_src (stable for ROS1/ROS2)\n\nYou may receive tensor streams via ROS pub/sub structure.\n\n\n\n\nYou may send tensor streams via ROS pub/sub structure.\n\n\nYou may receive tensor streams via ROS pub/sub structure.\n\n"});