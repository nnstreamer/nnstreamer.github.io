fragment_downloaded_cb({"url":"writing-tizen-csharp-apps.html#machine-learning","fragment":"Machine Learning\nMachine learning (ML) inference feature introduces how you can easily invoke the neural network model and get the inference output result effortlessly and efficiently.\nYou can use the following machine learning feature in your .NET applications:\nYou can use the Tizen.MachineLearning.Inference.SingleShot class, to load the existing neural network model or your own specific model from the storage. After loading the model, you can invoke it with a single instance of input data. Then, you can get the inference output result.\nYou can also use the Pipeline feature to manage the topology of data and the interconnection between processors and models. This feature is available in Native APIs from Tizen 5.5. However, this feature is not available in .NET APIs. This feature will be available in the .NET APIs from the next Tizen version.\nThe main features of the Tizen.MachineLearning.Inference are:\nManaging tensor information, which is the metadata: dimensions and types of tensors\nYou can configure the input and output Tensor Information such as its name, data type and dimension.\nLoading a neural network model and configuring a runtime environment\nYou can load the neural network model from storage and configure a runtime environment.\nInvoking the neural network model with input data\nAfter setting up the SingleShot instance with its required information, you can invoke the model with the input data and get the inference output result.\nFetching the inference result after invoking\nYou can fetch the inference result after invoking the respective model.\n\n\nManaging tensor information, which is the metadata: dimensions and types of tensors\nYou can configure the input and output Tensor Information such as its name, data type and dimension.\n\n\nLoading a neural network model and configuring a runtime environment\nYou can load the neural network model from storage and configure a runtime environment.\n\n\nInvoking the neural network model with input data\nAfter setting up the SingleShot instance with its required information, you can invoke the model with the input data and get the inference output result.\n\n\nFetching the inference result after invoking\nYou can fetch the inference result after invoking the respective model.\n\n\n"});