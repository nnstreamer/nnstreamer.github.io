fragment_downloaded_cb({"url":"nnstreamer_capi.html#machine-learning-inference","fragment":"Machine Learning Inference\nYou can easily create and efficiently execute data stream pipelines that consist of neural networks as filters in pipelines.\nThe main features of the Machine Learning Inference API include:\nConstruction of data pipeline based on GStreamer\nYou can compose the data stream pipeline through Machine Learning Inference with various elements of GStreamer and NNStreamer.\nSingle API and Pipeline API\nThere are two types of Machine Learning Inference API - Single API and Pipeline API.\nSingle API is useful for a simple usage scenario of neural network models. It allows invoking a neural network model with a single instance of input data for the model directly. It is useful if you have the input data pre-processed with the application itself and there are no complex interactions between neural network models, data processors, or data stream paths.\nPipeline API allows developers to construct and execute pipelines with multiple neural network models, multiple inputs and output nodes, multiple data processors, pre-and-post processors, and various data path manipulators. Besides, if the input is online data or streamed data, Pipeline API simplifies your application and improves its performance.\nSupport various neural network frameworks (NNFW)\nTensorFlow, TensorFlow-Lite, Caffe2, and PyTorch are the supported neural network frameworks. Neural network model files trained by such frameworks can be imported as filters of pipelines directly.\nCustom filters, which are neural network models implemented directly with programming languages including C/C++ and Python, maybe imported as filters of pipelines directly as well.\nNote\nThe devices powered by Tizen OS can contain TensorFlow-Lite only. Ensure that the neural network frameworks that you want to use are installed.\n\n\nConstruction of data pipeline based on GStreamer\nYou can compose the data stream pipeline through Machine Learning Inference with various elements of GStreamer and NNStreamer.\n\n\nSingle API and Pipeline API\nThere are two types of Machine Learning Inference API - Single API and Pipeline API.\nSingle API is useful for a simple usage scenario of neural network models. It allows invoking a neural network model with a single instance of input data for the model directly. It is useful if you have the input data pre-processed with the application itself and there are no complex interactions between neural network models, data processors, or data stream paths.\nPipeline API allows developers to construct and execute pipelines with multiple neural network models, multiple inputs and output nodes, multiple data processors, pre-and-post processors, and various data path manipulators. Besides, if the input is online data or streamed data, Pipeline API simplifies your application and improves its performance.\n\n\nSupport various neural network frameworks (NNFW)\nTensorFlow, TensorFlow-Lite, Caffe2, and PyTorch are the supported neural network frameworks. Neural network model files trained by such frameworks can be imported as filters of pipelines directly.\nCustom filters, which are neural network models implemented directly with programming languages including C/C++ and Python, maybe imported as filters of pipelines directly as well.\n\nNote\nThe devices powered by Tizen OS can contain TensorFlow-Lite only. Ensure that the neural network frameworks that you want to use are installed.\n\n\n\n"});