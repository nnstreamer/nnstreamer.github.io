fragment_downloaded_cb({"url":"API-reference.html#tizen-machinelearning-native-api-reference","fragment":"Tizen Machine-Learning Native API reference\nNNStreamer is acting as the library to execute inferences in Tizen; in other words, NNStreamer is the implementation of the Tizen's MachineLearning.Inference APIs.\nThis link provides native APIs (C-APIs) for Tizen Machine Learning.\nIn this document, the \"inference.single\" and \"inference.pipeline\" are implemented by NNStreamer.\nMachineLearning.Inference.Single allows using subplugins of tensor_filter to run the given neural network model, invoking the model directly from the application with a single-shot input data.\nMachineLearning.Inference.Pipeline allows describing and executing GStreamer pipelines including NNStreamer elements.\nNote that MachineLearning.Training and MachineLearning.Service are implemented by other packages in this organization.\nIf you are writing Tizen applications in C/C++ along with neural network inferences, you are supposed to use Tizen Machine-Learning.Inference Native APIs.\n"});