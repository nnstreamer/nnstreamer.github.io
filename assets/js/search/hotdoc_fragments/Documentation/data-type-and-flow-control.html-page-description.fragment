fragment_downloaded_cb({"url":"Documentation/data-type-and-flow-control.html#page-description","fragment":"Rank counting with other/tensor types\nAll NNStreamer's GStreamer data types as pad capabilities (other/tensor*) have the following common rules\nThe GStreamer pad capability has the following structure:\nThe buffer with offset 0 looks like the following with dim1=2, dim2=2, dim3=2, dim4=2:\n| dim4 | 0 |||||||| 1 |\n| dim3 | 0 |||| 1 |||| 0 |||| 1\n| dim2 | 0 || 1 || 0 || 1 || 0 || 1 || 0 || 1 |\n| dim1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 |\n| offset/type=uint8 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 |\n| offset/type=uint16 | 0 | 2 | 4 | 6 | 8 | 10 | 12 | 14 | 16 | 18 | 20 | 22 | 24 | 26 | 28 | 30 |\nTherefore, array in C corresponding to the buffer of a other/tensor becomes:\nNote that in some context (such as properties of tensor_* plugins), dimensions are described in a colon-separated string that allows omitting unused dimensions:\nIf rank = 2 (dim3 = 1 and dim4 = 1), then, it can be expressed as well as:\nBe careful! Colon-separated tensor dimension expression has the opposite order to the C-array type expression.\nother/tensors is defined to have multiple instances of other/tensor in a buffer of a single stream path. Compared to having multiple streams (thus multiple pads) with other/tensor that goes to or comes from a single element, having a single stream with other/tensors has the following advantages:\nThe GStreamer pad capability of other/tensors is as follows:\nThe buffer of other/tensors streams have multiple memory chunks. Each memory chunk represents one single tensor in the buffer format of other/tensor. With default configurations of Gstreamer 1.0, the maximum allowed number of memory chunks in a buffer is 16. Thus, with such configurations of Gstreamer 1.0, other/tensors may include up to 16 other/tensor.\nother/tensorsave, along with its typefind definition, is defined to enable to save other/tensors streams as files and load such files are other/tensors stream. With the definitions of headers defined with other/tensorsave, GStreamer can decode the given file and determine that the file belongs to other/tensorsave.\nThe detailed description of the file format is at Design External Save Format for other/tensor and other/tensors Stream for TypeFind\nIn general, tensor_* chooses the most recent timestamp when there are multiple candidates. For example, if we are merging/muxing/aggregating two frames from sinkpads, T and T+a, where a > 0, the source pads are supposed to have T+a.\nWe have the following principles for timestamp policies. Timestamping policies of tensor_* filters should follow the given principles.\nBesides timestamping, we have additional synchronization issues when there are merging streams. We need to determine which frames are going to be merged (or muxed) when we have multiple available and unused frames in an incoming sink pad. In general, we might say that the synchronization of frames determines which frames to be used for mux/merge and timestamping rule determins which timestamp to be used among the chosen frames for mux/merge.\nIn principle and by default,\nIn some usage cases, we may need to drop frames from a queue. With the timestamp values of frames, a queue may drop frames with different policies according to GStreamer applications. Such policies include:\nNote that in the case of many multi-modal neural networks, mux/merge elements are supposed to drop any older frames with incoming frames in the incoming (sink pad) queue.\nThis is an obvious case. The timestamp is copied to all source pads from the sink pads. We do not preserve original timestamps in Merge or Mux; thus, the processed timestamp after Mux or Merge will only be applied.\nUnlike mux and merge, aggregator merges tensors chronologically, not spatially.\nMoreover, unlike mux and merge, which merges entries into one entry, aggregator, depending on the properties, may divide or even simultaneously merge and divide entries. Thus, timestamping and synchronization may become much more complicated.\nThe timestamp of the outging buffer is timestamp of the oldest frame from the aggregated frames.\n\n\ntensor_filter, which is the main engine to communicate deep neural network frameworks and models, becomes simple and robust. With neural network models requiring multiple input tensors, if the input tensor streams are not fully synchronized, we need to somehow synchronize them and provide all input tensors at the same time to the model. Hereby, being fully synchronized means that the streams should provide new data simultaneously, which requires to have the exactly same framerate and timing, which is mostly impossible. With other/tensors and single input and output streams for tensor_filter, we can delegate the responsibilities of synchronization to GStreamer and its basic plugins, who are extremely good at such tasks.\nDuring transmissions on a stream pipeline, passing through various stream filters, we can guarantee that the same set of input tensors are being processed without the worries of synchronizations after the point of merging or muxing.\n\n\nTimestamp from the input source (sensors) should be preserved to sink elements.\nWhen there are multiple flows merging into one (an element with multiple sink pads), a timestamp of the most recent should be preserved.\n\nFor the current frame buffer in a sink pad, i in 1 ... n, FB(i), and T(FB(i)) is the timestamp of the current frame buffer, the timestamp of the corresponding frame buffer at source pads generated by FB(1) ... FB(n) is max(i = 1 .. n, T(FB(i))), where larger timestamp value means the more recent event.\nExample: when multiple frames of the same stream are combined by tensor_mux, according to the principle, the timestamp of the last frame of the combined frames is used for output timestamp.\nNote that this principle might cause confusion when we apply tensor_demux, where we may extract some \"old\" frames from incoming combined frames. However, as a single frame in a GStreamer stream has a single timestamp, we are going to ignore it for now.\n\n\n\n\nFor the current frame buffer in a sink pad, i in 1 ... n, FB(i), and T(FB(i)) is the timestamp of the current frame buffer, the timestamp of the corresponding frame buffer at source pads generated by FB(1) ... FB(n) is max(i = 1 .. n, T(FB(i))), where larger timestamp value means the more recent event.\nExample: when multiple frames of the same stream are combined by tensor_mux, according to the principle, the timestamp of the last frame of the combined frames is used for output timestamp.\nNote that this principle might cause confusion when we apply tensor_demux, where we may extract some \"old\" frames from incoming combined frames. However, as a single frame in a GStreamer stream has a single timestamp, we are going to ignore it for now.\n\n\nIf there are mutliple unused and available frames in a sink pad, unlike most media filters, we take a buffer that arrived most recently.\nFor more about the synchronization policies, see Synchronization policies at Mux and Merge\n\n\n\nLeaky on upstream: Drop more recent frames, keep older frames\nLeaky on downstream: Drop older frames, keep newer frames\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"});