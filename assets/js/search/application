urls_downloaded_cb({"token":"application","urls":[{"url":"AI-integration-on-Tizen.html#briefing","node_type":"p","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Briefing"],"context":{"gi-language":["default"]}},{"url":"AI-integration-on-Tizen.html#package-your-mls-into-rpk","node_type":"p","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Use ML Service API on Tizen","Package your mls into RPK\n"],"context":{"gi-language":["default"]}},{"url":"API-reference.html#tizen-machinelearning-native-api-reference","node_type":"p","page":"API reference","sections":["Tizen Machine-Learning Native API reference"],"context":{"gi-language":["default"]}},{"url":"component-description.html#gstreamer-elements-plugins","node_type":"ul","page":"Component description","sections":["Gstreamer Elements (Plugins)"],"context":{"gi-language":["default"]}},{"url":"component-description.html#gstreamer-stream-data-types","node_type":"p","page":"Component description","sections":["Gstreamer Stream Data Types"],"context":{"gi-language":["default"]}},{"url":"data-type-and-flow-control.html#othertensorsformatflexible","node_type":"p","page":"Data type and flow control","sections":["other/tensors","other/tensors,format=flexible"],"context":{"gi-language":["default"]}},{"url":"edge-ai.html#edgeai-example-applications-with-nnstreamer","node_type":"ul","page":"Edge-AI / Among-Device AI","sections":["Edge-AI Example Applications with NNStreamer"],"context":{"gi-language":["default"]}},{"url":"getting-started-android.html#prerequisite","node_type":"p","page":"Android","sections":["NNStreamer API Library for Android","Prerequisite"],"context":{"gi-language":["default"]}},{"url":"getting-started-android.html#using-model-file-with-scoped-storage","node_type":"p","page":"Android","sections":["NNStreamer API Library for Android","Build library","Using Model File with Scoped Storage"],"context":{"gi-language":["default"]}},{"url":"getting-started-tizen.html#getting-started-tizen-gbs","node_type":"ul","page":"Tizen GBS","sections":["Getting Started: Tizen GBS"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/README.html#headers","node_type":"p","page":"NNStreamer Elements","sections":["Headers"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#sink-pads","node_type":"p","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Sink Pads"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#supported-features","node_type":"ul","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Supported features"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_sink.html#properties","node_type":"ul","page":"tensor_sink","sections":["NNStreamer::tensor_sink","Properties"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_sink.html#signals","node_type":"ul","page":"tensor_sink","sections":["NNStreamer::tensor_sink","Signals"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_sink.html#supported-features","node_type":"p","page":"tensor_sink","sections":["NNStreamer::tensor_sink","Supported features"],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-camera-liveview-image-classification-decoded-by-user-application","node_type":"h2","page":"How to run examples","sections":["Usage Examples","Example : camera live-view image classification, decoded by user application."],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-camera-liveview-object-detection-decoded-by-user-application-with-tensorflow","node_type":"h2","page":"How to run examples","sections":["Usage Examples","Example : camera live-view object detection, decoded by user application with Tensorflow."],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-camera-liveview-object-detection-decoded-by-user-application-with-tensorflowlite","node_type":"h2","page":"How to run examples","sections":["Usage Examples","Example : camera live-view object detection, decoded by user application with Tensorflow-Lite."],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#table-of-contents","node_type":"ul","page":"How to run examples","sections":["Table of Contents"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.NET/OrientationDetection/README.html#description","node_type":"ul","page":"Orientation Detection","sections":["Tizen .NET (Wearable) NNStreamer Application Example - Orientation Detection","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.NET/OrientationDetection/README.html#tizen-net-wearable-nnstreamer-application-example-orientation-detection","node_type":"h1","page":"Orientation Detection","sections":["Tizen .NET (Wearable) NNStreamer Application Example - Orientation Detection"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.NET/TextClassification/README.html#tizen-net-nnstreamer-application-example-text-classification","node_type":"h2","page":"Text Classification","sections":["Tizen .NET NNStreamer Application Example - Text Classification"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/ImageClassification/README.html#description","node_type":"ul","page":"Image Classification (Pipeline)","sections":["Image Classification Sample App with NNStreamer","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/ImageClassification_SingleShot/README.html#description","node_type":"ul","page":"Image Classification (Single Shot)","sections":["Image Classification Sample App with NNStreamer Single Shot C-API","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/ObjectDetection/README.html#description","node_type":"ul","page":"Object Detection","sections":["Object Detection Sample App with NNStreamer Pipeline C-API","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/OrientationDetection/README.html#description","node_type":"ul","page":"Orientation Detection","sections":["Tizen Native (Wearable) NNStreamer Application Example - Orientation Detection","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/OrientationDetection/README.html#tizen-native-wearable-nnstreamer-application-example-orientation-detection","node_type":"h1","page":"Orientation Detection","sections":["Tizen Native (Wearable) NNStreamer Application Example - Orientation Detection"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/README.html#tizen-native-c-nnstreamer-example-application","node_type":"h1","page":"Tizen Native","sections":["Tizen native (c) NNStreamer Example Application"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.platform/Tizen_IoT_ImageClassification/README.html#image-classification-with-tizen-iot-platform","node_type":"p","page":"Image classification (Tizen IoT)","sections":["Image classification with Tizen IoT platform"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.platform/Tizen_IoT_text_classification_NonGUI/README.html#text-classification-with-tizen-iot-platform","node_type":"p","page":"Text classification (Tizen IoT)","sections":["Text classification with Tizen IoT platform"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_early_exit/README.html#nnstreamer-native-sample-application-early-exit-network","node_type":"h1","page":"Early Exit Network","sections":["NNStreamer Native Sample Application - Early exit network"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_join/README.html#nnstreamer-native-sample-application-join","node_type":"h2","page":"Join","sections":["NNStreamer Native Sample Application - join"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_tensorif/README.html#nnstreamer-native-sample-application-tensor_if","node_type":"h2","page":"Tensor if","sections":["NNStreamer Native Sample Application - tensor_if"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/index.html#nnstreamer-examples","node_type":"ul","page":"NNStreamer Examples","sections":["NNStreamer Examples"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_early_exit/README.html#nnstreamer-native-sample-application-early-exit-network","node_type":"h1","page":"Early exit","sections":["NNStreamer Native Sample Application - Early exit network"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_face_detection_tflite/README.html#introduction","node_type":"p","page":"Face detection","sections":["Ubuntu Native NNStreamer Application Example - Face Detection","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_face_detection_tflite/README.html#ubuntu-native-nnstreamer-application-example-face-detection","node_type":"h2","page":"Face detection","sections":["Ubuntu Native NNStreamer Application Example - Face Detection"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_gui_application/README.html#how-to-run","node_type":"p","page":"EZStreamer","sections":["Ubuntu Native NNStreamer GUI Application - EZStreamer","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_gui_application/README.html#introduction","node_type":"p","page":"EZStreamer","sections":["Ubuntu Native NNStreamer GUI Application - EZStreamer","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_gui_application/README.html#ubuntu-native-nnstreamer-gui-application-ezstreamer","node_type":"h2","page":"EZStreamer","sections":["Ubuntu Native NNStreamer GUI Application - EZStreamer"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_nnfw/README.html#ubuntu-native-nnstreamer-application-example-image-classification","node_type":"h2","page":"Image Classification (nnfw)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_tflite/README.html#ubuntu-native-nnstreamer-application-example-image-classification","node_type":"h2","page":"Image Classification (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_multi_model_tflite/README.html#ubuntu-native-nnstreamer-application-example-multimodel","node_type":"h2","page":"Multi-Model (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Multi-Model"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tensorflow_lite/README.html#ubuntu-native-nnstreamer-application-example-object-detection","node_type":"h2","page":"Object Detection (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Object Detection"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_pose_estimation_tflite/README.html#ubuntu-native-nnstreamer-application-example-pose-estimation-single-person","node_type":"h2","page":"Pose Estimation","sections":["Ubuntu Native NNStreamer Application Example - Pose Estimation (Single Person)"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_two_tensor_stream/README.html#native-nnstreamer-application-example-two-tensor-stream","node_type":"h2","page":"Two Tensor Stream","sections":["Native NNStreamer Application Example - Two Tensor Stream"],"context":{"gi-language":["default"]}},{"url":"nnstreamer_capi.html#machine-learning-inference","node_type":"ul","page":"NNStreamer C-API","sections":["Machine Learning Inference"],"context":{"gi-language":["default"]}},{"url":"nnstreamer_capi.html#prerequisites","node_type":"p","page":"NNStreamer C-API","sections":["Machine Learning Inference","Prerequisites"],"context":{"gi-language":["default"]}},{"url":"profiling-android-pipeline.html#get-the-tracing-data-of-your-android-application","node_type":"h2","page":"Profiling Android NNStreamer Pipeline with GstShark","sections":["[Android] Profiling NNStreamer Pipeline with GstShark","Get the tracing data of your Android Application"],"context":{"gi-language":["default"]}},{"url":"synchronization-policies-at-mux-merge.html#synchronization-policies-at-mux-and-merge","node_type":"p","page":"Synchronization policies","sections":["Synchronization policies at Mux and Merge"],"context":{"gi-language":["default"]}},{"url":"tools/README.html#you-can-find-nnstreamer-tools-here","node_type":"p","page":"NNStreamer Tools","sections":["Tools","You can find nnstreamer tools here."],"context":{"gi-language":["default"]}},{"url":"tools/debugging/README.html#case-study-2-tracing-individual-nnstreamer-elements-with-gst_debug-and-silent-property","node_type":"p","page":"Debugging tools","sections":["Debugging","Displaying debug messages with $GST_DEBUG","Case study 2: Tracing individual NNStreamer elements with GST_DEBUG and silent property"],"context":{"gi-language":["default"]}},{"url":"tools/debugging/README.html#generating-pipeline-graph-with-gst_debug_dump_dot_dir","node_type":"p","page":"Debugging tools","sections":["Debugging","Generating pipeline graph with $GST_DEBUG_DUMP_DOT_DIR"],"context":{"gi-language":["default"]}},{"url":"tools/debugging/README.html#gstreamer-application-macros-for-custom-gsteamer-application","node_type":"h4","page":"Debugging tools","sections":["Debugging","Generating pipeline graph with $GST_DEBUG_DUMP_DOT_DIR","GStreamer application macros for custom GSteamer application"],"context":{"gi-language":["default"]}},{"url":"tutorial4_query.html#client-pipeline1","node_type":"p","page":"T4. Edge pipeline - Query","sections":["Tutorial 4. Edge pipeline - Query","Run pipeline. (Object detection)","Client pipeline."],"context":{"gi-language":["default"]}},{"url":"tutorial5_gstreamer_api.html#tutorial-5-build-application-using-gstreamer-api","node_type":"h1","page":"T5. GStreamer API","sections":["Tutorial 5. Build application using GStreamer API"],"context":{"gi-language":["default"]}},{"url":"tutorials.html#basic-tutorials","node_type":"p","page":"Tutorials","sections":["Tutorials","Welcome to the NNStreamer tutorials.","Basic Tutorials"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#installing-visual-studio-tools-for-tizen","node_type":"ul","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Installing Visual Studio Tools for Tizen"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#loading-neural-network-model-and-configuring-runtime-environment","node_type":"p","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Loading Neural Network Model and Configuring Runtime Environment"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#prerequisites","node_type":"p","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Prerequisites"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#writing-a-tizen-net-application","node_type":"h1","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application"],"context":{"gi-language":["default"]}}]});