urls_downloaded_cb({"token":"video","urls":[{"url":"CONTRIBUTING.html#tsc-meeting","node_type":"p","page":"Contributing","sections":["Technical Steering Committee","TSC Meeting"],"context":{"gi-language":["default"]}},{"url":"component-description.html#gstreamer-elements-plugins","node_type":"ul","page":"Component description","sections":["Gstreamer Elements (Plugins)"],"context":{"gi-language":["default"]}},{"url":"component-description.html#gstreamer-stream-data-types","node_type":"p","page":"Component description","sections":["Gstreamer Stream Data Types"],"context":{"gi-language":["default"]}},{"url":"edge-ai.html#edgeai-example-applications-with-nnstreamer","node_type":"ul","page":"Edge-AI / Among-Device AI","sections":["Edge-AI Example Applications with NNStreamer"],"context":{"gi-language":["default"]}},{"url":"gst-launch-script-example.html#object-detection-using-outputcombination-option-of-the-tensor-filter","node_type":"ul","page":"gst-launch script examples","sections":["Script of nnstreamer_example_filter using tensorflow model (e.g., Mobilenet)","Object detection using output-combination option of the tensor filter"],"context":{"gi-language":["default"]}},{"url":"gst-launch-script-example.html#object-detection-using-tee","node_type":"ul","page":"gst-launch script examples","sections":["Script of nnstreamer_example_filter using tensorflow model (e.g., Mobilenet)","Object detection using tee"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_aggregator.html#disaggregation","node_type":"p","page":"tensor_aggregator","sections":["NNStreamer::tensor_aggregator","Supported features","Dis-aggregation"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#performance-characteristics","node_type":"ul","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Performance Characteristics"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#sink-pads","node_type":"p","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Sink Pads"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#source-pads","node_type":"p","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Source Pads"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#supported-features","node_type":"ul","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Supported features"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_decoder.html#properties","node_type":"ul","page":"tensor_decoder","sections":["NNStreamer::tensor_decoder","Properties"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_decoder.html#source-pads","node_type":"ul","page":"tensor_decoder","sections":["NNStreamer::tensor_decoder","Source Pads"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_decoder.html#supported-features","node_type":"table","page":"tensor_decoder","sections":["NNStreamer::tensor_decoder","Supported features"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_transform.html#properties","node_type":"ul","page":"tensor_transform","sections":["NNStreamer::tensor_transform","Properties"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#object-detection-using-output-combination-option","node_type":"p","page":"tensor_filter","sections":["NNStreamer::tensor_filter","In/Out combination","Comparison of tee and combination option","Object detection using output combination option"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#object-detection-using-tee","node_type":"p","page":"tensor_filter","sections":["NNStreamer::tensor_filter","In/Out combination","Comparison of tee and combination option","Object detection using tee"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_query/README.html#objectdetection","node_type":"p","page":"tensor_query","sections":["NNStreamer::tensor_query","Usage Example","Object-detection"],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#2-launch-two-pipelines","node_type":"p","page":"How to run examples","sections":["Usage Examples","Example : tensor sink","2. launch two pipelines"],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-camera-liveview-image-classification-decoded-by-user-application","node_type":"p","page":"How to run examples","sections":["Usage Examples","Example : camera live-view image classification, decoded by user application."],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-camera-liveview-object-detection-decoded-by-user-application-with-tensorflow","node_type":"p","page":"How to run examples","sections":["Usage Examples","Example : camera live-view object detection, decoded by user application with Tensorflow."],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-camera-liveview-object-detection-decoded-by-user-application-with-tensorflowlite","node_type":"p","page":"How to run examples","sections":["Usage Examples","Example : camera live-view object detection, decoded by user application with Tensorflow-Lite."],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-video-mixer-with-nnstreamer-plugin","node_type":"h2","page":"How to run examples","sections":["Usage Examples","Example : video mixer with NNStreamer plug-in"],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#table-of-contents","node_type":"ul","page":"How to run examples","sections":["Table of Contents"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.platform/Tizen_IoT_ImageClassification/README.html#image-classification-with-tizen-iot-platform","node_type":"p","page":"Image classification (Tizen IoT)","sections":["Image classification with Tizen IoT platform"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_join/README.html#introduction","node_type":"p","page":"Join","sections":["NNStreamer Native Sample Application - join","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_tensorif/README.html#graphical-description-of-pipeline-tensor_if-passthrough-action","node_type":"p","page":"Tensor if","sections":["NNStreamer Native Sample Application - tensor_if","Graphical description of pipeline - tensor_if passthrough action"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_tensorif/README.html#introduction","node_type":"p","page":"Tensor if","sections":["NNStreamer Native Sample Application - tensor_if","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_early_exit/README.html#introduction","node_type":"p","page":"Early exit","sections":["NNStreamer Native Sample Application - Early exit network","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_face_detection_tflite/README.html#introduction","node_type":"p","page":"Face detection","sections":["Ubuntu Native NNStreamer Application Example - Face Detection","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_nnfw/README.html#introduction","node_type":"p","page":"Image Classification (nnfw)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_tflite/README.html#introduction","node_type":"p","page":"Image Classification (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_multi_model_tflite/README.html#introduction","node_type":"p","page":"Multi-Model (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Multi-Model","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tensorflow_lite/README.html#ubuntu-native-nnstreamer-application-example-object-detection","node_type":"p","page":"Object Detection (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Object Detection"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tflite_2cam/README.html#object-detection-with-2-cameras","node_type":"p","page":"Object Detection (2 cam)","sections":["Object Detection with 2 cameras"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tflite_2cam/README.html#receiver","node_type":"p","page":"Object Detection (2 cam)","sections":["Object Detection with 2 cameras","Receiver"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_pose_estimation_tflite/README.html#introduction","node_type":"p","page":"Pose Estimation","sections":["Ubuntu Native NNStreamer Application Example - Pose Estimation (Single Person)","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_sink/README.html#sink_example_play","node_type":"p","page":"sink eample","sections":["sink_example_play"],"context":{"gi-language":["default"]}},{"url":"nnstreamer_capi.html#element-api","node_type":"ul","page":"NNStreamer C-API","sections":["Machine Learning Inference","Pipeline API","Element API"],"context":{"gi-language":["default"]}},{"url":"products.html#companies-known-to-use-nnstreamer","node_type":"p","page":"Products with NNStreamer","sections":["Companies known to use NNStreamer"],"context":{"gi-language":["default"]}},{"url":"products.html#research-based-on-nnstreamer","node_type":"ul","page":"Products with NNStreamer","sections":["Research","Research based on NNStreamer"],"context":{"gi-language":["default"]}},{"url":"tools/profiling/README.html#hawktracer","node_type":"p","page":"Profiling tools","sections":["Profiling","HawkTracer"],"context":{"gi-language":["default"]}},{"url":"tools/tracing/README.html#framerate-tracer","node_type":"p","page":"Tracing tools","sections":["Tracing","Using GstShark","Case study","Framerate tracer"],"context":{"gi-language":["default"]}},{"url":"tutorial1_playing_video.html#additional-description-for-used-elements","node_type":"ul","page":"T1. Playing Video","sections":["Tutorial 1. Playing video","Additional description for used elements."],"context":{"gi-language":["default"]}},{"url":"tutorial1_playing_video.html#playing-video","node_type":"h2","page":"T1. Playing Video","sections":["Tutorial 1. Playing video","Playing video!"],"context":{"gi-language":["default"]}},{"url":"tutorial1_playing_video.html#tutorial-1-playing-video","node_type":"h1","page":"T1. Playing Video","sections":["Tutorial 1. Playing video"],"context":{"gi-language":["default"]}},{"url":"tutorial2_object_detection.html#run-pipeline","node_type":"p","page":"T2. Object Detection","sections":["Tutorial 2. Object detection","Run pipeline."],"context":{"gi-language":["default"]}},{"url":"tutorial2_object_detection.html#tutorial-2-object-detection","node_type":"p","page":"T2. Object Detection","sections":["Tutorial 2. Object detection"],"context":{"gi-language":["default"]}},{"url":"tutorial3_pubsub_mqtt.html#run-pipeline-video-streaming","node_type":"h2","page":"T3. Edge pipeline - MQTT","sections":["Tutorial 3. Edge pipeline - MQTT","Run pipeline. (video streaming)"],"context":{"gi-language":["default"]}},{"url":"tutorial3_pubsub_mqtt.html#subscriber-pipeline","node_type":"p","page":"T3. Edge pipeline - MQTT","sections":["Tutorial 3. Edge pipeline - MQTT","Run pipeline. (video streaming)","Subscriber pipeline."],"context":{"gi-language":["default"]}},{"url":"tutorial3_pubsub_mqtt.html#tutorial-3-edge-pipeline-mqtt","node_type":"p","page":"T3. Edge pipeline - MQTT","sections":["Tutorial 3. Edge pipeline - MQTT"],"context":{"gi-language":["default"]}},{"url":"tutorial4_query.html#client-pipeline","node_type":"p","page":"T4. Edge pipeline - Query","sections":["Tutorial 4. Edge pipeline - Query","Run pipeline. (echo server)","Client pipeline."],"context":{"gi-language":["default"]}},{"url":"tutorial4_query.html#tutorial-4-edge-pipeline-query","node_type":"p","page":"T4. Edge pipeline - Query","sections":["Tutorial 4. Edge pipeline - Query"],"context":{"gi-language":["default"]}},{"url":"tutorials.html#subpages","node_type":"p","page":"Tutorials","sections":[],"context":{"gi-language":["default"]}},{"url":"writing-tizen-native-apps.html#about-the-tizen-mlinference-api-sets","node_type":"p","page":"Writing Tizen native apps","sections":["Writing a Tizen Native App","About the Tizen ML-Inference API Sets"],"context":{"gi-language":["default"]}}]});