urls_downloaded_cb({"token":"model","urls":[{"url":"AI-integration-on-Tizen.html#briefing","node_type":"p","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Briefing"],"context":{"gi-language":["default"]}},{"url":"AI-integration-on-Tizen.html#convert-pytorch-into-tflite-with-aiedgetorch","node_type":"p","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Prepare your model","Convert PyTorch into TFLite with ai-edge-torch\n"],"context":{"gi-language":["default"]}},{"url":"AI-integration-on-Tizen.html#make-pytorch-model","node_type":"h3","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Prepare your model","Make PyTorch model"],"context":{"gi-language":["default"]}},{"url":"AI-integration-on-Tizen.html#package-your-mls-into-rpk","node_type":"p","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Use ML Service API on Tizen","Package your mls into RPK\n"],"context":{"gi-language":["default"]}},{"url":"AI-integration-on-Tizen.html#prepare-your-model","node_type":"h2","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Prepare your model"],"context":{"gi-language":["default"]}},{"url":"AI-integration-on-Tizen.html#the-conf-file","node_type":"ul","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Use ML Service API on Tizen","The conf file"],"context":{"gi-language":["default"]}},{"url":"AI-integration-on-Tizen.html#use-ml-service-api-on-tizen","node_type":"p","page":"AI-Integration-on-Tizen","sections":["Use AI on Tizen","Use ML Service API on Tizen"],"context":{"gi-language":["default"]}},{"url":"API-reference.html#tizen-machinelearning-native-api-reference","node_type":"p","page":"API reference","sections":["Tizen Machine-Learning Native API reference"],"context":{"gi-language":["default"]}},{"url":"data-type-and-flow-control.html#othertensors","node_type":"ul","page":"Data type and flow control","sections":["other/tensors"],"context":{"gi-language":["default"]}},{"url":"data-type-and-flow-control.html#othertensorsformatflexible","node_type":"p","page":"Data type and flow control","sections":["other/tensors","other/tensors,format=flexible"],"context":{"gi-language":["default"]}},{"url":"getting-started-android.html#run-the-unittest-optional","node_type":"p","page":"Android","sections":["NNStreamer API Library for Android","Build library","Run the unit-test (Optional)"],"context":{"gi-language":["default"]}},{"url":"getting-started-android.html#using-model-file-with-scoped-storage","node_type":"h3","page":"Android","sections":["NNStreamer API Library for Android","Build library","Using Model File with Scoped Storage"],"context":{"gi-language":["default"]}},{"url":"getting-started-android.html#using-tensorflow-lite-nnapi-delegate","node_type":"p","page":"Android","sections":["NNStreamer API Library for Android","Build library","Using TensorFlow Lite NNAPI Delegate"],"context":{"gi-language":["default"]}},{"url":"gst-launch-script-example.html#audio-classification-using-yamnet-tflite-model","node_type":"h3","page":"gst-launch script examples","sections":["Audio classification using yamnet tflite model"],"context":{"gi-language":["default"]}},{"url":"gst-launch-script-example.html#script-of-nnstreamer_example_filter-using-tensorflow-lite-model-eg-mobilenet","node_type":"h3","page":"gst-launch script examples","sections":["Script of nnstreamer_example_filter using tensorflow lite model (e.g., Mobilenet)"],"context":{"gi-language":["default"]}},{"url":"gst-launch-script-example.html#script-of-nnstreamer_example_filter-using-tensorflow-model-eg-mobilenet","node_type":"h3","page":"gst-launch script examples","sections":["Script of nnstreamer_example_filter using tensorflow model (e.g., Mobilenet)"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_aggregator.html#disaggregation","node_type":"p","page":"tensor_aggregator","sections":["NNStreamer::tensor_aggregator","Supported features","Dis-aggregation"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_decoder.html#supported-features","node_type":"table","page":"tensor_decoder","sections":["NNStreamer::tensor_decoder","Supported features"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#example-launch-line","node_type":"p","page":"tensor_filter","sections":["NNStreamer::tensor_filter","In/Out combination","Input combination","Example launch line"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#example-launch-line-tensorflow","node_type":"p","page":"tensor_filter","sections":["NNStreamer::tensor_filter","Example launch line (tensorflow)"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#example-launch-line1","node_type":"p","page":"tensor_filter","sections":["NNStreamer::tensor_filter","In/Out combination","Output combination","Example launch line"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#nnstreamertensor_filter","node_type":"ul","page":"tensor_filter","sections":["NNStreamer::tensor_filter"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#output-combination","node_type":"p","page":"tensor_filter","sections":["NNStreamer::tensor_filter","In/Out combination","Output combination"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_query/README.html#client1","node_type":"ul","page":"tensor_query","sections":["NNStreamer::tensor_query","Usage Example","Object-detection","client"],"context":{"gi-language":["default"]}},{"url":"how-to-archive-large-data.html#how-to-archive-large-files-with-gitlfs","node_type":"p","page":"How to archive large files","sections":["How to archive large files with git-lfs"],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#build-examples-ubuntu-1604-and-1804","node_type":"ul","page":"How to run examples","sections":["Preparing nnstreamer for execution.","Build examples (Ubuntu 16.04 and 18.04)"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.NET/OrientationDetection/README.html#description","node_type":"ul","page":"Orientation Detection","sections":["Tizen .NET (Wearable) NNStreamer Application Example - Orientation Detection","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/ImageClassification/README.html#description","node_type":"ul","page":"Image Classification (Pipeline)","sections":["Image Classification Sample App with NNStreamer","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/ImageClassification_SingleShot/README.html#description","node_type":"ul","page":"Image Classification (Single Shot)","sections":["Image Classification Sample App with NNStreamer Single Shot C-API","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/ObjectDetection/README.html#description","node_type":"ul","page":"Object Detection","sections":["Object Detection Sample App with NNStreamer Pipeline C-API","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/OrientationDetection/README.html#description","node_type":"ul","page":"Orientation Detection","sections":["Tizen Native (Wearable) NNStreamer Application Example - Orientation Detection","Description"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.platform/Tizen_IoT_text_classification_NonGUI/README.html#text-classification-with-tizen-iot-platform","node_type":"p","page":"Text classification (Tizen IoT)","sections":["Text classification with Tizen IoT platform"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_early_exit/README.html#gstlaunchearlyexitnormalsh","node_type":"p","page":"Early Exit Network","sections":["NNStreamer Native Sample Application - Early exit network","prerequisite","gst-launch-early-exit-normal.sh"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_early_exit/README.html#introduction","node_type":"p","page":"Early Exit Network","sections":["NNStreamer Native Sample Application - Early exit network","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_early_exit/README.html#prerequisite","node_type":"p","page":"Early Exit Network","sections":["NNStreamer Native Sample Application - Early exit network","prerequisite"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_image_segmentation_tensorflow_lite/README.html#how-to-run","node_type":"ul","page":"Image Segmentation (edgeTPU)","sections":["NNStreamer Edge-AI Apllication - Image Segmentation (edgeTPU)","How to run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_face_detection_tflite/README.html#how-to-run","node_type":"p","page":"Face detection","sections":["Ubuntu Native NNStreamer Application Example - Face Detection","Introduction","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_nnfw/README.html#how-to-run","node_type":"p","page":"Image Classification (nnfw)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_tflite/README.html#how-to-run","node_type":"p","page":"Image Classification (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tensorflow_lite/README.html#how-to-run","node_type":"p","page":"Object Detection (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Object Detection","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tflite_2cam/README.html#how-to-run","node_type":"p","page":"Object Detection (2 cam)","sections":["Object Detection with 2 cameras","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_pose_estimation_tflite/README.html#how-to-run","node_type":"p","page":"Pose Estimation","sections":["Ubuntu Native NNStreamer Application Example - Pose Estimation (Single Person)","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_two_tensor_stream/README.html#how-to-run","node_type":"p","page":"Two Tensor Stream","sections":["Native NNStreamer Application Example - Two Tensor Stream","How to Run"],"context":{"gi-language":["default"]}},{"url":"nnstreamer_capi.html#machine-learning-inference","node_type":"ul","page":"NNStreamer C-API","sections":["Machine Learning Inference"],"context":{"gi-language":["default"]}},{"url":"nnstreamer_capi.html#single-api","node_type":"p","page":"NNStreamer C-API","sections":["Machine Learning Inference","Single API"],"context":{"gi-language":["default"]}},{"url":"tools/development/README.html#gettestmodelssh","node_type":"p","page":"Development tools","sections":["Development","getTestModels.sh"],"context":{"gi-language":["default"]}},{"url":"writing-subplugin-tensor-filter.html#flexibledynamic-inputoutput-tensor-dimension","node_type":"p","page":"Writing tensor filter subplugin","sections":["Writing a subplugin for NNStreamer's tensor_filter","More about the template subplugin code","Flexible/Dynamic Input/Output Tensor Dimension"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#fetching-inference-result","node_type":"p","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Fetching Inference Result"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#invoking-neural-network-model-using-input-data","node_type":"h2","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Invoking Neural Network Model using Input Data"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#loading-neural-network-model-and-configuring-runtime-environment","node_type":"h2","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Loading Neural Network Model and Configuring Runtime Environment"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#machine-learning","node_type":"ul","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Machine Learning"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#managing-tensor-information","node_type":"p","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Managing Tensor Information"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-csharp-apps.html#prerequisites","node_type":"p","page":"Writing Tizen C# apps","sections":["Writing a Tizen .NET Application","Prerequisites"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-native-apps.html#about-the-tizen-mlinference-api-sets","node_type":"p","page":"Writing Tizen native apps","sections":["Writing a Tizen Native App","About the Tizen ML-Inference API Sets"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-native-apps.html#general-flow-single","node_type":"p","page":"Writing Tizen native apps","sections":["Writing a Tizen Native App","General Flow / Single"],"context":{"gi-language":["default"]}}]});