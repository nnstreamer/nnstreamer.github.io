urls_downloaded_cb({"token":"stream","urls":[{"url":"CONTRIBUTING.html#tsc-meeting","node_type":"p","page":"Contributing","sections":["Technical Steering Committee","TSC Meeting"],"context":{"gi-language":["default"]}},{"url":"component-description.html#gstreamer-elements-plugins","node_type":"ul","page":"Component description","sections":["Gstreamer Elements (Plugins)"],"context":{"gi-language":["default"]}},{"url":"component-description.html#gstreamer-stream-data-types","node_type":"h1","page":"Component description","sections":["Gstreamer Stream Data Types"],"context":{"gi-language":["default"]}},{"url":"data-type-and-flow-control.html#othertensors","node_type":"ul","page":"Data type and flow control","sections":["other/tensors"],"context":{"gi-language":["default"]}},{"url":"data-type-and-flow-control.html#othertensorsformatflexible","node_type":"p","page":"Data type and flow control","sections":["other/tensors","other/tensors,format=flexible"],"context":{"gi-language":["default"]}},{"url":"data-type-and-flow-control.html#timestamps","node_type":"ul","page":"Data type and flow control","sections":["Flow control","Timestamps"],"context":{"gi-language":["default"]}},{"url":"edge-ai.html#what-is-edgeai-and-amongdevice-ai","node_type":"ul","page":"Edge-AI / Among-Device AI","sections":["What is Edge-AI and Among-Device AI?"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_aggregator.html#disaggregation","node_type":"p","page":"tensor_aggregator","sections":["NNStreamer::tensor_aggregator","Supported features","Dis-aggregation"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#flatbuffers-to-tensors-stream","node_type":"h3","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Usage Examples","flatbuffers to tensors stream"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#flexbuffers-to-tensors-stream","node_type":"h3","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Usage Examples","flexbuffers to tensors stream"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#protocol-buffers-to-tensors-stream","node_type":"h3","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Usage Examples","protocol buffers to tensors stream"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#sink-pads","node_type":"p","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Sink Pads"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_converter.html#supported-features","node_type":"ul","page":"tensor_converter","sections":["NNStreamer::tensor_converter","Supported features"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_decoder.html#tensor-stream-to-flatbuffers","node_type":"h3","page":"tensor_decoder","sections":["NNStreamer::tensor_decoder","Usage Examples","tensor stream to flatbuffers"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_decoder.html#tensor-stream-to-flexbuffers","node_type":"h3","page":"tensor_decoder","sections":["NNStreamer::tensor_decoder","Usage Examples","tensor stream to flexbuffers"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_decoder.html#tensor-stream-to-protocol-buffers","node_type":"h3","page":"tensor_decoder","sections":["NNStreamer::tensor_decoder","Usage Examples","tensor stream to protocol buffers"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_if.html#supported-features","node_type":"p","page":"tensor_if","sections":["NNStreamer::tensor_if","Supported features"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_sink.html#properties","node_type":"ul","page":"tensor_sink","sections":["NNStreamer::tensor_sink","Properties"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_sink.html#signals","node_type":"ul","page":"tensor_sink","sections":["NNStreamer::tensor_sink","Signals"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_src.html#motivation","node_type":"p","page":"tensor_source","sections":["NNStreamer::tensor_source","Motivation"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/elements/gsttensor_transform.html#supported-features","node_type":"ul","page":"tensor_transform","sections":["NNStreamer::tensor_transform","Supported Features"],"context":{"gi-language":["default"]}},{"url":"gst/nnstreamer/tensor_filter/README.html#nnstreamertensor_filter","node_type":"p","page":"tensor_filter","sections":["NNStreamer::tensor_filter"],"context":{"gi-language":["default"]}},{"url":"how-to-run-examples.html#example-camera-liveview-image-classification-w-gstlaunch-decoded-by-tensor_decoder","node_type":"p","page":"How to run examples","sections":["Usage Examples","Example : camera live-view image classification. w/ gst-launch, decoded by tensor_decoder"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.NET/OrientationDetection/README.html#introduction","node_type":"p","page":"Orientation Detection","sections":["Tizen .NET (Wearable) NNStreamer Application Example - Orientation Detection","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/Tizen.native/OrientationDetection/README.html#introduction","node_type":"p","page":"Orientation Detection","sections":["Tizen Native (Wearable) NNStreamer Application Example - Orientation Detection","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_tensorif/README.html#graphical-description-of-pipeline-tensor_if-passthrough-action","node_type":"p","page":"Tensor if","sections":["NNStreamer Native Sample Application - tensor_if","Graphical description of pipeline - tensor_if passthrough action"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/bash_script/example_tensorif/README.html#introduction","node_type":"p","page":"Tensor if","sections":["NNStreamer Native Sample Application - tensor_if","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/README.html#subpages","node_type":"p","page":"Ubuntu Native","sections":[],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_face_detection_tflite/README.html#introduction","node_type":"p","page":"Face detection","sections":["Ubuntu Native NNStreamer Application Example - Face Detection","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_nnfw/README.html#introduction","node_type":"p","page":"Image Classification (nnfw)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_image_classification_tflite/README.html#introduction","node_type":"p","page":"Image Classification (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Image Classification","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_multi_model_tflite/README.html#introduction","node_type":"p","page":"Multi-Model (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Multi-Model","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tensorflow_lite/README.html#ubuntu-native-nnstreamer-application-example-object-detection","node_type":"p","page":"Object Detection (tflite)","sections":["Ubuntu Native NNStreamer Application Example - Object Detection"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_object_detection_tflite_2cam/README.html#object-detection-with-2-cameras","node_type":"p","page":"Object Detection (2 cam)","sections":["Object Detection with 2 cameras"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_pose_estimation_tflite/README.html#introduction","node_type":"p","page":"Pose Estimation","sections":["Ubuntu Native NNStreamer Application Example - Pose Estimation (Single Person)","Introduction"],"context":{"gi-language":["default"]}},{"url":"nnstreamer-example/native/example_two_tensor_stream/README.html#native-nnstreamer-application-example-two-tensor-stream","node_type":"h2","page":"Two Tensor Stream","sections":["Native NNStreamer Application Example - Two Tensor Stream"],"context":{"gi-language":["default"]}},{"url":"nnstreamer_capi.html#element-api","node_type":"ul","page":"NNStreamer C-API","sections":["Machine Learning Inference","Pipeline API","Element API"],"context":{"gi-language":["default"]}},{"url":"nnstreamer_capi.html#machine-learning-inference","node_type":"ul","page":"NNStreamer C-API","sections":["Machine Learning Inference"],"context":{"gi-language":["default"]}},{"url":"synchronization-policies-at-mux-merge.html#synchronization-policies-at-mux-and-merge","node_type":"p","page":"Synchronization policies","sections":["Synchronization policies at Mux and Merge"],"context":{"gi-language":["default"]}},{"url":"tools/profiling/README.html#features","node_type":"ul","page":"Profiling tools","sections":["Profiling","HawkTracer","Features"],"context":{"gi-language":["default"]}},{"url":"tools/tracing/README.html#bitrate-tracer","node_type":"p","page":"Tracing tools","sections":["Tracing","Using GstShark","Case study","Bitrate tracer"],"context":{"gi-language":["default"]}},{"url":"tools/tracing/README.html#tracers-of-gstshark","node_type":"ul","page":"Tracing tools","sections":["Tracing","Using GstShark","Tracers of GstShark"],"context":{"gi-language":["default"]}},{"url":"tutorial1_playing_video.html#additional-description-for-used-elements","node_type":"ul","page":"T1. Playing Video","sections":["Tutorial 1. Playing video","Additional description for used elements."],"context":{"gi-language":["default"]}},{"url":"tutorial2_object_detection.html#run-pipeline","node_type":"p","page":"T2. Object Detection","sections":["Tutorial 2. Object detection","Run pipeline."],"context":{"gi-language":["default"]}},{"url":"tutorial2_object_detection.html#tutorial-2-object-detection","node_type":"p","page":"T2. Object Detection","sections":["Tutorial 2. Object detection"],"context":{"gi-language":["default"]}},{"url":"tutorial3_pubsub_mqtt.html#subscriber-pipeline1","node_type":"p","page":"T3. Edge pipeline - MQTT","sections":["Tutorial 3. Edge pipeline - MQTT","Run pipeline. (Object detection)","Subscriber pipeline."],"context":{"gi-language":["default"]}},{"url":"tutorial3_pubsub_mqtt.html#tutorial-3-edge-pipeline-mqtt","node_type":"p","page":"T3. Edge pipeline - MQTT","sections":["Tutorial 3. Edge pipeline - MQTT"],"context":{"gi-language":["default"]}},{"url":"writing-tizen-native-apps.html#general-flow-pipeline","node_type":"p","page":"Writing Tizen native apps","sections":["Writing a Tizen Native App","General Flow / Pipeline"],"context":{"gi-language":["default"]}}]});